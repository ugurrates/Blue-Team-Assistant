"""
Malware Analysis Tool - SOC-GRADE with Professional Tool Integration.

v1.0.0 Features:
- Multi-format file analysis via FileTypeRouter
- capa capability detection (Mandiant)
- FLOSS obfuscated string extraction (Mandiant)
- DIE packer/compiler detection
- binwalk embedded file analysis
- oletools Office macro analysis
- pdfid/pdf-parser PDF analysis
- Tool-based composite scoring
"""

from pathlib import Path
import asyncio
import datetime
from typing import Dict, Optional
import logging

# FileTypeRouter for intelligent routing
from ..analyzers.file_type_router import FileTypeRouter, FileType

# Analyzer imports (instance-based)
from ..analyzers.pe_analyzer import PEAnalyzer
from ..analyzers.pdf_analyzer import PDFAnalyzer
from ..analyzers.office_analyzer import OfficeAnalyzer
from ..analyzers.script_analyzer import ScriptAnalyzer
from ..analyzers.archive_analyzer import ArchiveAnalyzer
from ..analyzers.elf_analyzer import ELFAnalyzer
from ..analyzers.macho_analyzer import MachOAnalyzer
from ..analyzers.apk_analyzer import APKAnalyzer
from ..analyzers.firmware_analyzer import FirmwareAnalyzer

# Core integrations
from ..integrations.threat_intel import ThreatIntelligence
from ..integrations.llm_analyzer import LLMAnalyzer
from ..utils.helpers import calculate_file_hashes, get_file_info
from ..utils.ioc_extractor import IOCExtractor
from ..utils.string_extractor import StringExtractor
from ..utils.yara_scanner import YaraScanner
from ..utils.entropy_analyzer import EntropyAnalyzer  # v1.0.0

# Scoring
from ..scoring.tool_based_scoring import ToolBasedScoring
from ..scoring.intelligent_scoring import IntelligentScoring
from ..scoring.false_positive_filter import FalsePositiveFilter

from ..detection.rule_generator import RuleGenerator
from ..reporting.raw_output_collector import RawOutputCollector

logger = logging.getLogger(__name__)


class MalwareAnalyzer:
    """
    SOC-GRADE Malware Analysis with Professional Tool Integration.
    
    v1.0.0 Features:
    - Multi-format file analysis via FileTypeRouter
    - capa capability detection (Mandiant)
    - FLOSS obfuscated string extraction (Mandiant)
    - DIE packer/compiler detection
    - binwalk embedded file analysis
    - oletools Office macro analysis
    - pdfid/pdf-parser PDF analysis
    - Tool-based composite scoring
    """
    
    # Analyzer instances (lazy loaded)
    _analyzers: Dict[FileType, object] = {}
    
    def __init__(self, config: Dict):
        """Initialize malware analyzer with all integrations."""
        self.config = config
        self.threat_intel = ThreatIntelligence(config)
        self.llm_analyzer = LLMAnalyzer(config)
        self.string_extractor = StringExtractor()
        self.yara_scanner = YaraScanner()
        
        # Sandbox integration
        from ..integrations.sandbox_integration import SandboxIntegration
        self.sandbox = SandboxIntegration(config)
        
        # Cross-tool integration (set by parent)
        self.ioc_investigator = None
        
        # Initialize analyzers
        self._init_analyzers()
    
    def _init_analyzers(self):
        """Initialize file type specific analyzers as INSTANCES."""
        try:
            self._analyzers = {
                FileType.PE: PEAnalyzer(),
                FileType.ELF: ELFAnalyzer(),
                FileType.MACHO: MachOAnalyzer(),
                FileType.OFFICE: OfficeAnalyzer(),
                FileType.PDF: PDFAnalyzer(),
                FileType.SCRIPT: ScriptAnalyzer(),
                FileType.APK: APKAnalyzer(),
                FileType.ARCHIVE: ArchiveAnalyzer(),
                FileType.FIRMWARE: FirmwareAnalyzer(),
            }
            logger.info("[MALWARE] All analyzers initialized (instance-based)")
        except Exception as e:
            logger.warning(f"[MALWARE] Analyzer init warning: {e}")
            self._analyzers = {}
    
    def _get_analyzer(self, file_type: FileType) -> Optional[object]:
        """Get analyzer instance for file type."""
        if file_type in self._analyzers:
            return self._analyzers[file_type]
        
        # Lazy load if not initialized
        analyzer_class = FileTypeRouter.get_analyzer_class(file_type)
        if analyzer_class:
            try:
                self._analyzers[file_type] = analyzer_class()
                return self._analyzers[file_type]
            except Exception as e:
                logger.error(f"[MALWARE] Failed to create analyzer for {file_type}: {e}")
        
        return None
    
    async def analyze(self, file_path: str) -> Dict:
        """
        SOC-GRADE file analysis with professional tool integration.
        
        Pipeline:
        1. File type detection (FileTypeRouter)
        2. Hash reputation check
        3. Sandbox report check
        4. Static analysis with professional tools (capa, FLOSS, DIE, etc.)
        5. String extraction & IOC detection
        6. YARA scanning
        7. Tool-based composite scoring
        8. LLM analysis
        9. Detection rule generation
        """
        logger.info(f"[MALWARE] Analyzing: {Path(file_path).name}")
        
        # Initialize Raw Output Collector
        raw_collector = RawOutputCollector()
        raw_collector.record_pipeline_step('init', 'analysis_start', 'started')
        
        try:
            # ==================== FILE INFO ====================
            file_info = get_file_info(file_path)
            if 'error' in file_info:
                return {'error': file_info['error']}
            raw_collector.capture_file_info(file_info)
            
            # Calculate hashes
            hashes = calculate_file_hashes(file_path)
            raw_collector.capture_hash_output(hashes)
            raw_collector.record_pipeline_step('triage', 'file_info', 'completed')
            
            # ==================== FILE TYPE DETECTION ====================
            logger.info("[MALWARE] Detecting file type via FileTypeRouter...")
            file_type, type_metadata = FileTypeRouter.detect_file_type(file_path)
            logger.info(f"[MALWARE] Detected: {file_type.value} (method: {type_metadata.get('detection_method', 'unknown')})")
            raw_collector.record_pipeline_step('triage', 'file_type_detection', 'completed')
            
            # ==================== HASH REPUTATION ====================
            logger.info("[MALWARE] Checking hash reputation...")
            intel_results = await self.threat_intel.investigate_ioc_comprehensive(
                hashes['sha256'], 'sha256'
            )
            hash_score = IntelligentScoring.calculate_ioc_score(intel_results)
            raw_collector.capture_api_response('hash_reputation', intel_results)
            raw_collector.record_pipeline_step('triage', 'hash_reputation', 'completed')
            
            # ==================== SANDBOX ANALYSIS ====================
            logger.info("[MALWARE] Checking sandbox reports...")
            sandbox_results = await self.sandbox.check_file_sandboxes(hashes['sha256'])
            raw_collector.capture_sandbox_results(sandbox_results)
            raw_collector.record_pipeline_step('dynamic', 'sandbox_check', 'completed')
            
            # ==================== STATIC ANALYSIS WITH PROFESSIONAL TOOLS ====================
            logger.info(f"[MALWARE] Running {file_type.value} analyzer with professional tools...")
            
            analyzer = self._get_analyzer(file_type)
            if analyzer:
                # Call analyze() method on INSTANCE (not static!)
                static_analysis = analyzer.analyze(file_path)
                analysis_tools = static_analysis.get('analysis_tools', [])
                logger.info(f"[MALWARE] Tools used: {analysis_tools}")
            else:
                static_analysis = self._fallback_analysis(file_path)
                analysis_tools = ['basic']
            
            raw_collector.capture_static_analysis(static_analysis)
            raw_collector.record_pipeline_step('static', 'professional_analysis', 'completed')
            
            # ==================== ENTROPY ANALYSIS (v1.0.0) ====================
            logger.info("[MALWARE] Calculating file entropy...")
            entropy_analysis = EntropyAnalyzer.analyze_file_entropy(file_path)
            raw_collector.capture_tool_output('entropy', entropy_analysis)
            raw_collector.record_pipeline_step('static', 'entropy_analysis', 'completed')
            
            # ==================== EXTRACT TOOL RESULTS ====================
            
            # Capabilities (capa)
            capabilities = static_analysis.get('capabilities', {})
            if capabilities.get('success'):
                logger.info(f"[CAPA] {len(capabilities.get('capabilities', []))} capabilities detected")
                raw_collector.capture_tool_output('capa', capabilities)
            
            # Obfuscated strings (FLOSS)
            obfuscated_strings = static_analysis.get('strings', {})
            if obfuscated_strings.get('decoded_count', 0) > 0:
                logger.info(f"[FLOSS] {obfuscated_strings['decoded_count']} decoded strings found")
                raw_collector.capture_tool_output('floss', obfuscated_strings)
            
            # Packer detection (DIE)
            packer_info = static_analysis.get('packer_detection', {})
            if packer_info.get('packers') or packer_info.get('protectors'):
                logger.info(f"[DIE] Packer/Protector: {packer_info}")
                raw_collector.capture_tool_output('diec', packer_info)
            
            # Embedded files (binwalk)
            embedded_files = static_analysis.get('embedded_files', {})
            if embedded_files:
                raw_collector.capture_tool_output('binwalk', embedded_files)
            
            # ==================== STRING EXTRACTION ====================
            logger.info("[MALWARE] Extracting strings...")
            strings_data = self.string_extractor.extract_strings(file_path, min_length=4)
            all_strings = strings_data['ascii'] + strings_data['unicode']
            
            logger.info("[MALWARE] Categorizing suspicious strings...")
            suspicious_strings = self.string_extractor.categorize_suspicious_strings(all_strings)
            
            logger.info("[MALWARE] Extracting IOCs from strings...")
            string_iocs = self.string_extractor.extract_iocs_from_strings(all_strings)
            registry_keys = self.string_extractor.extract_registry_keys(all_strings)
            mutexes = self.string_extractor.extract_mutexes(all_strings)
            user_agents = self.string_extractor.extract_user_agents(all_strings)
            interesting_strings = self.string_extractor.get_interesting_strings(all_strings, limit=50)
            
            raw_collector.capture_strings_output({
                'total_count': len(all_strings),
                'ascii': strings_data['ascii'][:500],
                'unicode': strings_data['unicode'][:500],
                'urls': string_iocs.get('urls', []),
                'ips': string_iocs.get('ipv4', []),
                'registry': registry_keys,
                'mutexes': mutexes,
                'suspicious': interesting_strings,
                'categories': suspicious_strings
            })
            raw_collector.record_pipeline_step('static', 'string_extraction', 'completed')
            
            # ==================== YARA SCANNING ====================
            logger.info("[MALWARE] Scanning with YARA rules...")
            yara_matches = self.yara_scanner.scan_file(file_path)
            yara_analysis = YaraScanner.interpret_matches(yara_matches)
            
            raw_collector.capture_yara_output({
                'matches': yara_matches,
                'malware_families': yara_analysis.get('malware_families', []),
                'severity': yara_analysis.get('severity', 'NONE')
            })
            raw_collector.record_pipeline_step('static', 'yara_scan', 'completed')
            
            # ==================== IOC INVESTIGATION ====================
            all_iocs = self._aggregate_iocs(static_analysis, string_iocs, obfuscated_strings)
            ioc_results = []
            
            if self.ioc_investigator and all_iocs:
                logger.info(f"[MALWARE] Investigating {len(all_iocs)} IOCs...")
                for ioc in all_iocs[:10]:
                    try:
                        ioc_result = await self.ioc_investigator.investigate(ioc)
                        ioc_results.append(ioc_result)
                    except Exception as e:
                        logger.warning(f"[MALWARE] IOC investigation failed for {ioc}: {e}")
            
            raw_collector.record_pipeline_step('correlation', 'ioc_investigation', 'completed')
            
            # ==================== TOOL-BASED SCORING ====================
            logger.info("[MALWARE] Calculating tool-based composite score...")
            
            scoring_input = {
                'capabilities': capabilities,
                'strings': obfuscated_strings,
                'packer_detection': packer_info,
                'pe_analysis': static_analysis.get('pe_analysis', {}),
                'static_analysis': static_analysis,  # Full static analysis results
                'yara_matches': yara_matches,
                'hash_score': hash_score,
                'ioc_results': ioc_results,
                'sandbox_results': sandbox_results,
            }
            
            scoring_result = ToolBasedScoring.calculate_file_score(scoring_input)
            composite_score = scoring_result.combined_score
            verdict = scoring_result.verdict
            contributing_factors = scoring_result.contributing_factors
            
            logger.info(f"[MALWARE] Tool-based score: {composite_score}/100 ({verdict})")
            logger.info(f"[MALWARE] Contributing factors: {contributing_factors}")
            
            # False positive check
            fp_file_data = {
                'file_name': Path(file_path).name,
                'filename': Path(file_path).name,
                'signature': static_analysis.get('signature', {}),
                'sha256': hashes.get('sha256', ''),
                **file_info
            }
            is_fp, fp_reason = FalsePositiveFilter.is_false_positive(fp_file_data, composite_score)
            raw_collector.record_pipeline_step('verdict', 'fp_check', 'completed')
            
            # ==================== MITRE ATT&CK MAPPING (v1.0.0) ====================
            logger.info("[MALWARE] Generating MITRE ATT&CK mapping...")
            mitre_mapping = self._generate_mitre_mapping(static_analysis, sandbox_results, capabilities)
            raw_collector.record_pipeline_step('analysis', 'mitre_mapping', 'completed')
            
            # ==================== LLM ANALYSIS ====================
            logger.info("[MALWARE] Running AI analysis...")
            
            # v1.0.0: Extract entropy values - handle both structures
            if 'file_entropy' in entropy_analysis:
                llm_entropy = entropy_analysis['file_entropy'].get('overall_entropy', 0)
                llm_entropy_cat = entropy_analysis['file_entropy'].get('interpretation', {}).get('category', 'UNKNOWN')
            else:
                llm_entropy = entropy_analysis.get('overall_entropy', 0)
                llm_entropy_cat = entropy_analysis.get('interpretation', {}).get('category', 'UNKNOWN')
            
            llm_input = {
                'file_info': file_info,
                'file_type': file_type.value,
                'hashes': hashes,
                'static_analysis': static_analysis,
                'capabilities': capabilities,
                'threat_indicators': static_analysis.get('threat_indicators', []),
                'suspicious_patterns': static_analysis.get('suspicious_patterns', {}),
                'string_iocs': string_iocs,
                'composite_score': composite_score,
                'verdict': verdict,
                'entropy': llm_entropy,
                'entropy_category': llm_entropy_cat,
            }
            llm_analysis = await self.llm_analyzer.analyze_file(llm_input)
            raw_collector.record_pipeline_step('ai', 'llm_analysis', 'completed')
            
            # ==================== DETECTION RULES ====================
            logger.info("[MALWARE] Generating detection rules...")
            detection_rules = RuleGenerator.generate_file_rules({
                'filename': Path(file_path).name,
                'sha256': hashes['sha256'],
                'md5': hashes['md5'],
                'suspicious_indicators': contributing_factors,
                'iocs': all_iocs[:20],
                'yara_tags': yara_analysis.get('tags', []),
            })
            
            # ==================== FINAL RESULT ====================
            result = {
                'file_info': file_info,
                'file_type': file_type.value,
                'file_type_metadata': type_metadata,
                'hashes': hashes,
                'hash_score': hash_score,
                
                # Professional Analysis
                'static_analysis': static_analysis,
                'entropy_analysis': entropy_analysis,  # v1.0.0
                'capabilities': capabilities,
                'obfuscated_strings': obfuscated_strings,
                'packer_detection': packer_info,
                'embedded_files': embedded_files,
                'analysis_tools': analysis_tools,
                
                'string_analysis': {
                    'total_strings': len(all_strings),
                    'ascii_strings': len(strings_data['ascii']),
                    'unicode_strings': len(strings_data['unicode']),
                    'suspicious_categories': suspicious_strings,
                    'registry_keys': registry_keys[:20],
                    'mutexes': mutexes,
                    'user_agents': user_agents,
                    'interesting_strings': interesting_strings
                },
                
                'yara_analysis': {
                    'matches': yara_matches,
                    'interpretation': yara_analysis
                },
                
                'sandbox_analysis': sandbox_results,
                'mitre_mapping': mitre_mapping,  # v1.0.0
                
                'ioc_analysis': {
                    'total_iocs': len(all_iocs),
                    'investigated': len(ioc_results),
                    'malicious_iocs': sum(1 for r in ioc_results if r.get('verdict') == 'MALICIOUS'),
                    'results': ioc_results
                },
                
                # Tool-Based Scoring
                'scoring': {
                    'composite_score': composite_score,
                    'tool_scores': scoring_result.breakdown,
                    'contributing_factors': contributing_factors,
                    'confidence': scoring_result.confidence,
                },
                'composite_score': composite_score,
                'verdict': verdict,
                'is_false_positive': is_fp,
                'false_positive_reason': fp_reason,
                
                'llm_analysis': llm_analysis,
                'detection_rules': detection_rules,
                'raw_output': raw_collector.get_all_raw_data()
            }
            
            logger.info(f"[MALWARE] Analysis complete: {verdict} (score: {composite_score}/100)")
            
            return result
            
        except Exception as e:
            logger.error(f"[MALWARE] Analysis failed: {e}", exc_info=True)
            return {'error': str(e)}
    
    def _aggregate_iocs(self, static_analysis: Dict, string_iocs: Dict, obfuscated: Dict) -> list:
        """Aggregate IOCs from all sources."""
        all_iocs = set()
        
        # From static analysis
        static_iocs = static_analysis.get('iocs', {})
        if static_iocs:
            all_iocs.update(static_iocs.get('urls', []))
            all_iocs.update(static_iocs.get('ipv4', []))
            all_iocs.update(static_iocs.get('domains', []))
        
        # From string extraction
        all_iocs.update(string_iocs.get('urls', []))
        all_iocs.update(string_iocs.get('ipv4', []))
        all_iocs.update(string_iocs.get('domains', []))
        
        # From obfuscated strings (FLOSS)
        if obfuscated:
            all_iocs.update(obfuscated.get('urls', []))
            all_iocs.update(obfuscated.get('ips', []))
            all_iocs.update(obfuscated.get('domains', []))
        
        return list(all_iocs)
    
    def _prepare_llm_input(self, static_analysis: Dict, capabilities: Dict, strings: Dict) -> str:
        """Prepare comprehensive input for LLM analysis."""
        lines = ["# File Analysis Summary for AI Review\n"]
        
        lines.append(f"## File Type: {static_analysis.get('file_type', 'Unknown')}")
        tools = static_analysis.get('analysis_tools', [])
        lines.append(f"## Analysis Tools: {', '.join(tools) if tools else 'basic'}\n")
        
        # Threat indicators
        threat_indicators = static_analysis.get('threat_indicators', [])
        if threat_indicators:
            lines.append("## Threat Indicators:")
            for ind in threat_indicators[:15]:
                lines.append(f"- {ind}")
        
        # Capabilities (capa)
        if capabilities.get('success') and capabilities.get('capabilities'):
            lines.append("\n## Detected Capabilities (capa):")
            for cap in capabilities.get('capabilities', [])[:10]:
                if isinstance(cap, dict):
                    lines.append(f"- {cap.get('name', 'Unknown')} [{cap.get('namespace', '')}]")
                    if cap.get('attack_ids'):
                        lines.append(f"  ATT&CK: {', '.join(cap['attack_ids'])}")
                else:
                    lines.append(f"- {cap}")
        
        # Obfuscated Strings (FLOSS)
        if strings.get('decoded_count', 0) > 0:
            lines.append(f"\n## Obfuscated Strings (FLOSS):")
            lines.append(f"- Decoded strings: {strings.get('decoded_count', 0)}")
            lines.append(f"- Stack strings: {strings.get('stack_count', 0)}")
            if strings.get('suspicious_strings'):
                lines.append("- Suspicious decoded strings:")
                for s in strings['suspicious_strings'][:5]:
                    lines.append(f"  `{s[:60]}...`")
        
        lines.append("\n## Analysis Request:")
        lines.append("Based on these findings, provide:")
        lines.append("1. Likely malware family/type classification")
        lines.append("2. Primary attack capabilities and techniques")
        lines.append("3. Recommended containment and remediation steps")
        lines.append("4. Detection rule suggestions")
        
        return '\n'.join(lines)
    
    def _fallback_analysis(self, file_path: str) -> Dict:
        """Fallback analysis for unsupported file types."""
        return {
            'file_type': 'Unknown',
            'analysis_tools': ['basic'],
            'threat_indicators': [],
            'note': 'Limited analysis - unsupported file type'
        }
    
    def _extract_hash_findings(self, intel_results: Dict) -> list:
        """Extract key findings from hash reputation check."""
        findings = []
        
        for source_name, source_data in intel_results.items():
            if isinstance(source_data, dict):
                if source_data.get('found') or source_data.get('malicious'):
                    finding = f"{source_name}: "
                    if 'detections' in source_data:
                        finding += f"{source_data['detections']} detections"
                    elif 'malware' in source_data:
                        finding += f"Malware: {source_data['malware']}"
                    elif 'threat' in source_data:
                        finding += f"Threat: {source_data['threat']}"
                    else:
                        finding += "Flagged"
                    findings.append(finding)
        
        return findings
    
    def _generate_mitre_mapping(self, static_analysis: Dict, sandbox: Dict, capabilities: Dict) -> list:
        """
        Generate MITRE ATT&CK mapping from analysis results.
        
        v1.0.0: New feature - aggregates MITRE techniques from multiple sources.
        """
        techniques = []
        seen = set()
        
        # 1. From sandbox results (most reliable)
        sandbox_summary = sandbox.get('summary', {})
        sandbox_mitre = sandbox_summary.get('mitre_techniques', [])
        for t in sandbox_mitre:
            if t and t not in seen:
                techniques.append({
                    'technique_id': t,
                    'source': 'sandbox',
                    'confidence': 'high'
                })
                seen.add(t)
        
        # 2. From capabilities (capa)
        capa_attacks = capabilities.get('attack_techniques', [])
        for t in capa_attacks:
            tech_id = t.get('technique_id', t) if isinstance(t, dict) else t
            if tech_id and tech_id not in seen:
                techniques.append({
                    'technique_id': tech_id,
                    'source': 'capa',
                    'confidence': 'high'
                })
                seen.add(tech_id)
        
        # 3. From static analysis patterns
        patterns = static_analysis.get('suspicious_patterns', {}).get('categories', {})
        
        pattern_to_mitre = {
            'execution': ['T1059', 'T1059.001'],  # Command/Script Interpreter
            'persistence': ['T1547', 'T1053'],     # Boot/Scheduled Task
            'evasion': ['T1027', 'T1140'],         # Obfuscation/Deobfuscation
            'credential': ['T1003', 'T1555'],      # Credential Dumping
            'discovery': ['T1082', 'T1083'],       # System/File Discovery
            'download': ['T1105'],                 # Ingress Tool Transfer
            'privilege': ['T1548'],                # Abuse Elevation
            'defense_evasion': ['T1562', 'T1070'], # Impair Defenses/Indicator Removal
            'collection': ['T1560', 'T1119'],      # Archive/Automated Collection
            'exfiltration': ['T1041'],             # Exfiltration Over C2
        }
        
        for cat, count_data in patterns.items():
            cat_lower = cat.lower()
            if cat_lower in pattern_to_mitre:
                count = count_data.get('count', 0) if isinstance(count_data, dict) else 0
                if count > 0:
                    for tech_id in pattern_to_mitre[cat_lower]:
                        if tech_id not in seen:
                            techniques.append({
                                'technique_id': tech_id,
                                'source': 'static_analysis',
                                'category': cat,
                                'confidence': 'medium'
                            })
                            seen.add(tech_id)
        
        return techniques
