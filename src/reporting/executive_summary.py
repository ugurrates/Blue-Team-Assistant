"""
Author: Ugur AtesExecutive Summary Generator for Blue Team Assistant Reports."""

from typing import Dict
from datetime import datetime
import logging

logger = logging.getLogger(__name__)
class ExecutiveSummary:
    """Generate executive summaries for SOC reports."""
    
    @staticmethod
    def generate_file_summary(result: Dict) -> str:
        """
        Generate executive summary for file analysis.
        
        Args:
            result: File analysis result dict
        
        Returns:
            Formatted executive summary string
        """
        verdict = result.get('verdict', 'UNKNOWN')
        score = result.get('composite_score', 0)
        file_info = result.get('file_info', {})
        filename = file_info.get('name', 'Unknown')
        sha256 = result.get('hashes', {}).get('sha256', 'N/A')
        sha256_short = sha256[:16] + '...' if len(sha256) > 16 else sha256
        
        # Determine risk level and actions
        if score >= 70:
            risk_level = "ğŸ”´ CRITICAL"
            action = "IMMEDIATE ACTION REQUIRED"
            recommendation = "Block immediately, isolate affected systems, initiate incident response"
        elif score >= 50:
            risk_level = "ğŸŸ  HIGH"
            action = "URGENT REVIEW NEEDED"
            recommendation = "Quarantine file, investigate execution history, monitor for related activity"
        elif score >= 30:
            risk_level = "ğŸŸ¡ MEDIUM"
            action = "FURTHER ANALYSIS RECOMMENDED"
            recommendation = "Review in sandbox environment, check for false positive indicators"
        else:
            risk_level = "ğŸŸ¢ LOW"
            action = "ROUTINE MONITORING"
            recommendation = "Continue monitoring, no immediate action required"
        
        # Build key findings
        findings = []
        
        # Check YARA
        yara = result.get('yara_analysis', {})
        if yara.get('matches'):
            families = yara.get('interpretation', {}).get('malware_families', [])
            if families:
                findings.append(f"Malware family identified: {', '.join(families[:2])}")
            else:
                findings.append(f"YARA matches: {len(yara.get('matches', []))} rules triggered")
        
        # Check sandbox
        sandbox = result.get('sandbox_analysis', {})
        if sandbox:
            summary = sandbox.get('summary', {})
            if summary.get('behaviors'):
                findings.append(f"Suspicious behaviors: {', '.join(summary['behaviors'][:3])}")
        
        # Check IOCs
        iocs = result.get('ioc_analysis', {})
        if iocs.get('malicious_iocs', 0) > 0:
            findings.append(f"Malicious IOCs found: {iocs['malicious_iocs']} embedded indicators")
        
        # Check static analysis
        static = result.get('static_analysis', {})
        if static.get('signature', {}).get('signed') == False:
            findings.append("File is UNSIGNED - increased risk")
        
        # Check string categories
        string_analysis = result.get('string_analysis', {})
        categories = string_analysis.get('suspicious_categories', {})
        if categories:
            findings.append(f"Suspicious string categories: {', '.join(list(categories.keys())[:3])}")
        
        # Check threat intel
        threat_intel = result.get('threat_intel', {})
        if threat_intel.get('sources_flagged', 0) > 0:
            findings.append(f"Threat intel: {threat_intel['sources_flagged']}/{threat_intel.get('sources_checked', 0)} sources flagged")
        
        if not findings:
            findings.append("No critical indicators detected")
        
        findings_str = '\n'.join([f"â”‚  â€¢ {f}" for f in findings[:5]])
        
        summary = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  EXECUTIVE SUMMARY - FILE ANALYSIS                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ RISK ASSESSMENT
â”‚
â”‚  Risk Level    : {risk_level}
â”‚  Threat Score  : {score}/100
â”‚  Verdict       : {verdict}
â”‚  Action        : {action}
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€ QUICK FACTS
â”‚
â”‚  File          : {filename}
â”‚  Size          : {file_info.get('size_human', 'Unknown')}
â”‚  Type          : {file_info.get('type', 'Unknown')}
â”‚  SHA256        : {sha256_short}
â”‚  Detection     : {threat_intel.get('sources_flagged', 0)}/{threat_intel.get('sources_checked', 0)} sources flagged
â”‚  YARA Matches  : {len(yara.get('matches', []))} rules
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€ KEY FINDINGS
â”‚
{findings_str}
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€ RECOMMENDATION
â”‚
â”‚  {recommendation}
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
        logger.info(f"[SUMMARY] Generated file summary: {verdict} ({score}/100)")
        return summary
    
    @staticmethod
    def generate_email_summary(result: Dict) -> str:
        """
        Generate executive summary for email analysis.
        
        Args:
            result: Email analysis result dict
        
        Returns:
            Formatted executive summary string
        """
        verdict = result.get('verdict', 'UNKNOWN')
        score = result.get('composite_score', 0)
        email_data = result.get('email_data', {})
        sender = email_data.get('from', 'Unknown')
        subject = email_data.get('subject', 'N/A')
        if len(subject) > 50:
            subject = subject[:47] + '...'
        
        # Determine risk level
        if verdict == 'PHISHING' or score >= 70:
            risk_level = "ğŸ”´ CRITICAL - PHISHING"
            action = "IMMEDIATE BLOCK & PURGE"
            recommendation = "Block sender, delete from all mailboxes, notify affected users"
        elif verdict == 'SPAM' or score >= 50:
            risk_level = "ğŸŸ  HIGH - LIKELY MALICIOUS"
            action = "BLOCK & INVESTIGATE"
            recommendation = "Quarantine emails, investigate sender reputation, check for user interaction"
        elif score >= 30:
            risk_level = "ğŸŸ¡ MEDIUM - SUSPICIOUS"
            action = "REVIEW REQUIRED"
            recommendation = "Review email content, verify sender legitimacy, monitor for similar messages"
        else:
            risk_level = "ğŸŸ¢ LOW - LIKELY LEGITIMATE"
            action = "ROUTINE MONITORING"
            recommendation = "No immediate action required"
        
        # Auth results
        spf = email_data.get('spf', 'unknown').upper()
        dkim = email_data.get('dkim', 'unknown').upper()
        dmarc = email_data.get('dmarc', 'unknown').upper()
        
        spf_icon = "âœ…" if spf == "PASS" else "âŒ" if spf == "FAIL" else "âš ï¸"
        dkim_icon = "âœ…" if dkim == "PASS" else "âŒ" if dkim == "FAIL" else "âš ï¸"
        dmarc_icon = "âœ…" if dmarc == "PASS" else "âŒ" if dmarc == "FAIL" else "âš ï¸"
        
        # Build key findings
        findings = []
        
        # Authentication failures
        auth_failures = []
        if spf == 'FAIL':
            auth_failures.append('SPF')
        if dkim == 'FAIL':
            auth_failures.append('DKIM')
        if dmarc == 'FAIL':
            auth_failures.append('DMARC')
        if auth_failures:
            findings.append(f"Authentication failures: {', '.join(auth_failures)}")
        
        # Advanced analysis
        advanced = result.get('advanced_analysis', {})
        if advanced.get('brand_impersonation'):
            findings.append(f"Brand impersonation detected: {advanced['brand_impersonation'].get('brand', 'Unknown')}")
        if advanced.get('lookalike_domains'):
            domains = advanced['lookalike_domains'][:2]
            findings.append(f"Lookalike domains: {', '.join([d.get('domain', '') for d in domains])}")
        if advanced.get('link_mismatches'):
            findings.append(f"Link-text mismatches: {len(advanced['link_mismatches'])} found")
        
        # Forensics
        forensics = result.get('forensics', {})
        if forensics.get('forensics_score', 0) >= 50:
            findings.append(f"Forensics risk score: {forensics['forensics_score']}/100")
        
        # IOCs
        iocs = result.get('ioc_analysis', {})
        if iocs.get('malicious_iocs', 0) > 0:
            findings.append(f"Malicious IOCs: {iocs['malicious_iocs']} indicators flagged")
        
        # Attachments
        attachments = result.get('attachment_analysis', {})
        if attachments.get('malicious_attachments', 0) > 0:
            findings.append(f"Malicious attachments: {attachments['malicious_attachments']} detected")
        
        if not findings:
            findings.append("No critical indicators detected")
        
        findings_str = '\n'.join([f"â”‚  â€¢ {f}" for f in findings[:5]])
        
        summary = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  EXECUTIVE SUMMARY - EMAIL ANALYSIS                                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ RISK ASSESSMENT
â”‚
â”‚  Risk Level    : {risk_level}
â”‚  Threat Score  : {score}/100
â”‚  Verdict       : {verdict}
â”‚  Action        : {action}
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€ EMAIL DETAILS
â”‚
â”‚  From          : {sender}
â”‚  Subject       : {subject}
â”‚  URLs Found    : {len(email_data.get('urls', []))}
â”‚  Attachments   : {len(email_data.get('attachments', []))}
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€ AUTHENTICATION STATUS
â”‚
â”‚  SPF           : {spf_icon} {spf}
â”‚  DKIM          : {dkim_icon} {dkim}
â”‚  DMARC         : {dmarc_icon} {dmarc}
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€ KEY FINDINGS
â”‚
{findings_str}
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€ RECOMMENDATION
â”‚
â”‚  {recommendation}
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
        logger.info(f"[SUMMARY] Generated email summary: {verdict} ({score}/100)")
        return summary
    
    @staticmethod
    def generate_ioc_summary(result: Dict, ioc: str) -> str:
        """
        Generate executive summary for IOC analysis.
        
        Args:
            result: IOC analysis result dict
            ioc: The IOC value
        
        Returns:
            Formatted executive summary string
        """
        verdict = result.get('verdict', 'UNKNOWN')
        score = result.get('threat_score', 0)
        ioc_type = result.get('ioc_type', 'unknown')
        sources_checked = result.get('sources_checked', 0)
        sources_flagged = result.get('sources_flagged', 0)
        
        # Determine risk level
        if verdict == 'MALICIOUS' or score >= 70:
            risk_level = "ğŸ”´ CRITICAL - MALICIOUS"
            action = "IMMEDIATE BLOCK"
            recommendation = "Block at firewall/proxy, hunt for connections, isolate affected systems"
        elif verdict == 'SUSPICIOUS' or score >= 40:
            risk_level = "ğŸŸ  HIGH - SUSPICIOUS"
            action = "MONITOR & INVESTIGATE"
            recommendation = "Add to watchlist, review connection logs, correlate with other activity"
        elif score >= 20:
            risk_level = "ğŸŸ¡ MEDIUM - LOW RISK"
            action = "PASSIVE MONITORING"
            recommendation = "Document finding, continue monitoring, no immediate action required"
        else:
            risk_level = "ğŸŸ¢ LOW - CLEAN"
            action = "NO ACTION NEEDED"
            recommendation = "No threats detected, safe to proceed"
        
        summary = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  EXECUTIVE SUMMARY - IOC INVESTIGATION                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€ RISK ASSESSMENT
â”‚
â”‚  Risk Level    : {risk_level}
â”‚  Threat Score  : {score}/100
â”‚  Verdict       : {verdict}
â”‚  Action        : {action}
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€ IOC DETAILS
â”‚
â”‚  IOC           : {ioc}
â”‚  Type          : {ioc_type.upper()}
â”‚  Sources       : {sources_flagged}/{sources_checked} flagged
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€ RECOMMENDATION
â”‚
â”‚  {recommendation}
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
        logger.info(f"[SUMMARY] Generated IOC summary: {verdict} ({score}/100)")
        return summary
