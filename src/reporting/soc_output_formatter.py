"""
Author: Ugur Ates
SOC Output Formatter - Professional IR/SOC-Grade Output
Based on comprehensive SOC/Blue Team/Incident Responder workflow specifications.
"""

from typing import Dict, List
from datetime import datetime
import logging

logger = logging.getLogger(__name__)
class SOCOutputFormatter:
    """
    Professional SOC-grade output formatter.
    
    Generates comprehensive, actionable reports for:
    - Email Forensics (7-step IR workflow)
    - Malware Analysis (PE static analysis)
    - IOC Investigation (22+ sources)
    """
    
    # Box drawing characters
    BOX_TOP = "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    BOX_MID = "â•‘"
    BOX_BOT = "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    BOX_SINGLE_TOP = "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
    BOX_SINGLE_MID = "â”‚"
    BOX_SINGLE_BOT = "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
    
    SECTION_SEP = "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    
    @classmethod
    def format_email_report(cls, result: Dict, email_path: str) -> str:
        """
        Format comprehensive email forensics report.
        
        Follows professional IR workflow:
        1. Header Forensics
        2. Sender Verification
        3. Content Analysis
        4. Link/URL Analysis
        5. Attachment Analysis
        6. IOC Extraction & Correlation
        7. Verdict & Recommendations
        """
        lines = []
        
        # ==================== HEADER ====================
        lines.append(cls.BOX_TOP)
        lines.append(f"{cls.BOX_MID}  ğŸ“§ EMAIL FORENSIC ANALYSIS REPORT{' ' * 42}{cls.BOX_MID}")
        lines.append(f"{cls.BOX_MID}  Analysis Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}{' ' * 30}{cls.BOX_MID}")
        lines.append(cls.BOX_BOT)
        lines.append("")
        
        # ==================== VERDICT BOX ====================
        verdict = result.get('verdict', 'UNKNOWN')
        composite_score = result.get('composite_score', 0)
        
        verdict_emoji = {'PHISHING': 'ğŸ£', 'SUSPICIOUS': 'âš ï¸', 'SPAM': 'ğŸ“§', 'CLEAN': 'âœ…', 'UNKNOWN': 'â“'}
        risk_level = "CRITICAL" if composite_score >= 85 else "HIGH" if composite_score >= 60 else "MEDIUM" if composite_score >= 30 else "LOW"
        
        lines.append(cls.BOX_SINGLE_TOP)
        lines.append(f"{cls.BOX_SINGLE_MID}  {verdict_emoji.get(verdict, '')} VERDICT: {verdict}{' ' * (60 - len(verdict))}{cls.BOX_SINGLE_MID}")
        lines.append(f"{cls.BOX_SINGLE_MID}  Composite Score: {composite_score}/100 ({risk_level}){' ' * (48 - len(str(composite_score)) - len(risk_level))}{cls.BOX_SINGLE_MID}")
        lines.append(cls.BOX_SINGLE_BOT)
        lines.append("")
        
        # ==================== SECTION 1: EMAIL METADATA ====================
        lines.append(cls.SECTION_SEP)
        lines.append(" SECTION 1: EMAIL METADATA")
        lines.append(cls.SECTION_SEP)
        lines.append("")
        
        email_data = result.get('email_data', {})
        lines.append(f"  Subject    : {email_data.get('subject', 'N/A')}")
        lines.append(f"  From       : {email_data.get('from', 'N/A')}")
        lines.append(f"  To         : {email_data.get('to', 'N/A')}")
        lines.append(f"  Date       : {email_data.get('date', 'N/A')}")
        lines.append(f"  Message-ID : {email_data.get('message_id', 'N/A')}")
        
        # Anomalies
        advanced = result.get('advanced_analysis', {})
        header_analysis = advanced.get('header_analysis', {})
        anomalies = header_analysis.get('anomalies', [])
        
        if anomalies:
            lines.append("")
            lines.append("  âš ï¸  ANOMALIES DETECTED:")
            for anomaly in anomalies[:5]:
                lines.append(f"      â€¢ {anomaly}")
        lines.append("")
        
        # ==================== SECTION 2: HEADER FORENSICS ====================
        lines.append(cls.SECTION_SEP)
        lines.append(" SECTION 2: HEADER FORENSICS")
        lines.append(cls.SECTION_SEP)
        lines.append("")
        
        forensics = result.get('forensics', {})
        
        # Timeline
        timeline = forensics.get('timeline', [])
        if timeline:
            lines.append(f"â”Œâ”€ DELIVERY TIMELINE ({len(timeline)} hops)")
            lines.append("â”‚")
            
            for hop in timeline[:6]:
                hop_num = hop.get('hop_number', '?')
                from_server = hop.get('from_server', 'Unknown')
                from_ip = hop.get('from_ip', '')
                timestamp = hop.get('timestamp', hop.get('timestamp_raw', 'Unknown'))
                protocol = hop.get('protocol', '')
                
                lines.append(f"â”‚  HOP {hop_num} â”‚ {timestamp}")
                lines.append(f"â”‚        â”‚ From: {from_server}" + (f" [{from_ip}]" if from_ip else ""))
                if hop.get('by_server'):
                    lines.append(f"â”‚        â”‚ To: {hop.get('by_server')}")
                if protocol:
                    lines.append(f"â”‚        â”‚ Protocol: {protocol}")
                lines.append("â”‚")
            
            if len(timeline) > 6:
                lines.append(f"â”‚  ... {len(timeline) - 6} more hops")
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # Authentication
        auth = forensics.get('authentication', {})
        if auth:
            lines.append("â”Œâ”€ AUTHENTICATION RESULTS")
            lines.append("â”‚")
            
            spf = auth.get('spf', {})
            spf_status = spf.get('status', 'UNKNOWN')
            spf_emoji = "âœ…" if spf_status.upper() == 'PASS' else "âŒ" if spf_status.upper() in ['FAIL', 'SOFTFAIL'] else "âšª"
            lines.append(f"â”‚  SPF     â”‚ {spf_emoji} {spf_status.upper()}")
            if spf.get('details'):
                lines.append(f"â”‚          â”‚ {spf.get('details')}")
            
            dkim = auth.get('dkim', {})
            dkim_status = dkim.get('status', 'UNKNOWN')
            dkim_emoji = "âœ…" if dkim_status.upper() == 'PASS' else "âŒ" if dkim_status.upper() == 'FAIL' else "âšª"
            lines.append(f"â”‚  DKIM    â”‚ {dkim_emoji} {dkim_status.upper()}")
            if dkim.get('domain'):
                lines.append(f"â”‚          â”‚ Domain: {dkim.get('domain')}")
            
            dmarc = auth.get('dmarc', {})
            dmarc_status = dmarc.get('status', 'UNKNOWN')
            dmarc_emoji = "âœ…" if dmarc_status.upper() == 'PASS' else "âŒ" if dmarc_status.upper() == 'FAIL' else "âšª"
            lines.append(f"â”‚  DMARC   â”‚ {dmarc_emoji} {dmarc_status.upper()}")
            
            lines.append("â”‚")
            
            overall = auth.get('overall_pass', False)
            if overall:
                lines.append("â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
                lines.append("â”‚  â”‚ âœ… AUTHENTICATION VERDICT: PASS            â”‚")
                lines.append("â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            else:
                lines.append("â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
                lines.append("â”‚  â”‚ ğŸš¨ AUTHENTICATION VERDICT: FAIL            â”‚")
                lines.append("â”‚  â”‚    Authentication mechanisms failed.       â”‚")
                lines.append("â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # Relay Anomalies
        relay = forensics.get('relay_analysis', {})
        suspicious_hops = relay.get('suspicious_hops', [])
        time_anomalies = relay.get('time_anomalies', [])
        
        if suspicious_hops or time_anomalies:
            lines.append("â”Œâ”€ RELAY PATH ANOMALIES")
            
            if suspicious_hops:
                lines.append(f"â”‚  ğŸš¨ Suspicious Hops: {len(suspicious_hops)}")
                for sh in suspicious_hops[:3]:
                    reasons = ', '.join(sh.get('reasons', []))
                    lines.append(f"â”‚    Hop {sh.get('hop')}: {reasons}")
            
            if time_anomalies:
                lines.append(f"â”‚  ğŸš¨ Time Anomalies: {len(time_anomalies)}")
                for ta in time_anomalies[:3]:
                    lines.append(f"â”‚    {ta.get('hops')}: {ta.get('issue')}")
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # Sender Reputation
        reputation = forensics.get('sender_reputation', {})
        if reputation:
            lines.append("â”Œâ”€ SENDER REPUTATION")
            lines.append(f"â”‚  Risk Score: {reputation.get('risk_score', 0)}/100")
            lines.append(f"â”‚  From: {reputation.get('from_address', 'Unknown')}")
            lines.append(f"â”‚  Domain: {reputation.get('from_domain', 'Unknown')}")
            
            suspicious_patterns = reputation.get('suspicious_patterns', [])
            if suspicious_patterns:
                lines.append("â”‚")
                lines.append("â”‚  ğŸš¨ Suspicious Patterns:")
                for pattern in suspicious_patterns[:5]:
                    lines.append(f"â”‚    â€¢ {pattern}")
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== SECTION 3: CONTENT ANALYSIS ====================
        lines.append(cls.SECTION_SEP)
        lines.append(" SECTION 3: CONTENT ANALYSIS")
        lines.append(cls.SECTION_SEP)
        lines.append("")
        
        content_issues_found = False
        
        # Brand Impersonation
        brand_impersonation = advanced.get('brand_impersonation', [])
        if brand_impersonation:
            content_issues_found = True
            lines.append("â”Œâ”€ BRAND IMPERSONATION")
            for imp in brand_impersonation[:5]:
                brand = imp.get('brand', 'Unknown')
                risk = imp.get('risk', 'UNKNOWN')
                reason = imp.get('reason', '')
                lines.append(f"â”‚  ğŸš¨ {brand} - {risk}")
                if reason:
                    lines.append(f"â”‚     {reason}")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # HTML Obfuscation
        html_obfuscation = advanced.get('html_obfuscation', {})
        risk_score = html_obfuscation.get('risk_score', 0)
        if risk_score > 0:
            content_issues_found = True
            lines.append("â”Œâ”€ HTML OBFUSCATION ANALYSIS")
            lines.append(f"â”‚  Risk Score: {risk_score}/100")
            
            if risk_score > 20:
                lines.append("â”‚")
                techniques = html_obfuscation.get('techniques', {})
                if techniques.get('zero_size_fonts', 0) > 0:
                    lines.append(f"â”‚  ğŸš¨ Zero-size fonts: {techniques['zero_size_fonts']} instances")
                if techniques.get('hidden_elements', 0) > 0:
                    lines.append(f"â”‚  ğŸš¨ Hidden elements: {techniques['hidden_elements']} instances")
                if techniques.get('white_on_white', 0) > 0:
                    lines.append(f"â”‚  ğŸš¨ White-on-white text: {techniques['white_on_white']} instances")
                if techniques.get('base64_content', 0) > 0:
                    lines.append(f"â”‚  ğŸš¨ Base64 encoded content: {techniques['base64_content']} instances")
            else:
                lines.append("â”‚  âœ… No significant obfuscation detected")
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # QR Codes
        qr_detection = advanced.get('qr_detection', {})
        qr_codes = qr_detection.get('qr_codes', [])
        if qr_codes:
            content_issues_found = True
            lines.append("â”Œâ”€ QR CODE DETECTION")
            lines.append(f"â”‚  ğŸš¨ {len(qr_codes)} QR CODE(S) FOUND")
            for qr in qr_codes[:3]:
                lines.append(f"â”‚  Location: {qr.get('location', 'Unknown')}")
                if qr.get('decoded_url'):
                    lines.append(f"â”‚  Decoded URL: {qr.get('decoded_url')[:60]}")
            lines.append("â”‚")
            lines.append("â”‚  âš ï¸  QR codes in emails are HIGH RISK - often bypass URL filters")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # If no content issues found, show that explicitly
        if not content_issues_found:
            lines.append("â”Œâ”€ CONTENT ANALYSIS SUMMARY")
            lines.append("â”‚  âœ… No brand impersonation detected")
            lines.append("â”‚  âœ… No HTML obfuscation detected")
            lines.append("â”‚  âœ… No QR codes detected")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== SECTION 4: LINK ANALYSIS ====================
        lines.append(cls.SECTION_SEP)
        lines.append(" SECTION 4: LINK ANALYSIS")
        lines.append(cls.SECTION_SEP)
        lines.append("")
        
        link_issues_found = False
        
        # Show all URLs from email
        email_urls = email_data.get('urls', [])
        email_domains = email_data.get('domains', [])
        
        if email_urls or email_domains:
            lines.append(f"â”Œâ”€ URL INVENTORY ({len(email_urls)} URLs, {len(email_domains)} domains)")
            for i, url in enumerate(email_urls[:10], 1):
                # Truncate long URLs
                display_url = url[:70] + "..." if len(url) > 70 else url
                lines.append(f"â”‚  URL #{i}: {display_url}")
            
            if len(email_urls) > 10:
                lines.append(f"â”‚  ... and {len(email_urls) - 10} more URLs")
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # Link-Text Mismatches
        link_mismatches = advanced.get('link_mismatches', [])
        if link_mismatches:
            link_issues_found = True
            lines.append(f"â”Œâ”€ LINK-TEXT MISMATCHES ({len(link_mismatches)} found)")
            for i, mismatch in enumerate(link_mismatches[:5], 1):
                displayed = mismatch.get('displayed_url', 'Unknown')
                actual = mismatch.get('actual_url', 'Unknown')
                lines.append(f"â”‚")
                lines.append(f"â”‚  URL #{i} - ğŸš¨ MISMATCH")
                lines.append(f"â”‚  â”œâ”€ Displayed : {displayed[:60]}")
                lines.append(f"â”‚  â””â”€ Actual    : {actual[:60]}")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # Lookalike Domains
        lookalike_domains = advanced.get('lookalike_domains', [])
        if lookalike_domains:
            link_issues_found = True
            lines.append(f"â”Œâ”€ LOOKALIKE DOMAIN DETECTION ({len(lookalike_domains)} found)")
            for domain in lookalike_domains[:5]:
                domain_name = domain.get('domain', 'Unknown')
                legitimate = domain.get('legitimate', 'Unknown')
                similarity = domain.get('similarity', 0)
                technique = domain.get('technique', 'Unknown')
                
                # Handle similarity format
                if isinstance(similarity, str):
                    similarity_str = similarity
                elif isinstance(similarity, (int, float)):
                    similarity_str = f"{similarity:.0%}" if similarity <= 1 else f"{similarity}%"
                else:
                    similarity_str = str(similarity)
                
                lines.append(f"â”‚")
                lines.append(f"â”‚  DOMAIN: {domain_name}")
                lines.append(f"â”‚  â”œâ”€ Impersonating    : {legitimate}")
                lines.append(f"â”‚  â”œâ”€ Technique        : {technique}")
                lines.append(f"â”‚  â”œâ”€ Visual Similarity: {similarity_str}")
                lines.append(f"â”‚  â””â”€ Risk Level       : CRITICAL")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # Summary if no link issues
        if not link_issues_found and not email_urls:
            lines.append("â”Œâ”€ LINK ANALYSIS SUMMARY")
            lines.append("â”‚  âœ… No URLs found in email")
            lines.append("â”‚  âœ… No link-text mismatches detected")
            lines.append("â”‚  âœ… No lookalike domains detected")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        elif not link_issues_found:
            lines.append("â”Œâ”€ LINK ANALYSIS SUMMARY")
            lines.append("â”‚  âœ… No link-text mismatches detected")
            lines.append("â”‚  âœ… No lookalike domains detected")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== SECTION 5: ATTACHMENT ANALYSIS ====================
        attachment_analysis = result.get('attachment_analysis', {})
        attachments = attachment_analysis.get('attachments', [])
        
        if attachments:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 5: ATTACHMENT ANALYSIS")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            lines.append(f"â”Œâ”€ ATTACHMENT INVENTORY ({len(attachments)} files)")
            
            for att in attachments:
                filename = att.get('filename', 'Unknown')
                verdict = att.get('verdict', 'UNKNOWN')
                score = att.get('composite_score', 0)
                
                verdict_emoji = 'ğŸ¦ ' if verdict == 'MALICIOUS' else 'âš ï¸' if verdict == 'SUSPICIOUS' else 'âœ…'
                
                lines.append(f"â”‚")
                lines.append(f"â”‚  ğŸ“ {filename}")
                lines.append(f"â”‚  â”Œ" + "â”€" * 70)
                
                file_info = att.get('file_info', {})
                if file_info:
                    lines.append(f"â”‚  â”‚ Size: {file_info.get('size_bytes', 0):,} bytes")
                    lines.append(f"â”‚  â”‚ Type: {file_info.get('mime_type', 'Unknown')}")
                
                hashes = att.get('hashes', {})
                if hashes.get('sha256'):
                    lines.append(f"â”‚  â”‚ SHA256: {hashes.get('sha256', 'Unknown')[:32]}...")
                
                hash_score = att.get('hash_score', 0)
                if hash_score > 0:
                    lines.append(f"â”‚  â”‚ Hash Reputation: ğŸš¨ {hash_score}/100")
                
                yara = att.get('yara_analysis', {})
                if yara and yara.get('matches'):
                    families = yara.get('interpretation', {}).get('malware_families', [])
                    if families:
                        lines.append(f"â”‚  â”‚ YARA: {', '.join(families)}")
                
                lines.append(f"â”‚  â”‚")
                lines.append(f"â”‚  â”‚ {verdict_emoji} VERDICT: {verdict} (Score: {score}/100)")
                lines.append(f"â”‚  â””" + "â”€" * 70)
            
            lines.append("â”‚")
            mal_count = sum(1 for a in attachments if a.get('verdict') == 'MALICIOUS')
            sus_count = sum(1 for a in attachments if a.get('verdict') == 'SUSPICIOUS')
            lines.append(f"â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            lines.append(f"â”‚  â”‚ ATTACHMENT SUMMARY                          â”‚")
            lines.append(f"â”‚  â”‚ Total: {len(attachments)} â”‚ Malicious: {mal_count} â”‚ Suspicious: {sus_count}    â”‚")
            lines.append(f"â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== SECTION 6: IOC ANALYSIS ====================
        ioc_analysis = result.get('ioc_analysis', {})
        ioc_results = ioc_analysis.get('results', [])  # This is a list, not a dict
        
        # Always show Section 6 header
        lines.append(cls.SECTION_SEP)
        lines.append(" SECTION 6: IOC EXTRACTION & THREAT INTELLIGENCE")
        lines.append(cls.SECTION_SEP)
        lines.append("")
        
        total = ioc_analysis.get('total_iocs', len(ioc_results))
        malicious = ioc_analysis.get('malicious_iocs', 0)
        suspicious = ioc_analysis.get('suspicious_iocs', 0)
        
        if total > 0 or email_data.get('urls') or email_data.get('domains') or email_data.get('ips'):
            lines.append(f"â”Œâ”€ EXTRACTED IOCs (Total: {total})")
            lines.append("â”‚")
            
            # Group results by type
            urls = [r for r in ioc_results if r.get('ioc_type') == 'url']
            domains = [r for r in ioc_results if r.get('ioc_type') == 'domain']
            ips = [r for r in ioc_results if r.get('ioc_type') in ['ipv4', 'ip']]
            
            # URLs
            if urls:
                mal_urls = [u for u in urls if u.get('verdict') == 'MALICIOUS']
                sus_urls = [u for u in urls if u.get('verdict') == 'SUSPICIOUS']
                lines.append(f"â”‚  URLs ({len(urls)} investigated)")
                
                for url in mal_urls[:3]:
                    ioc = url.get('ioc', 'Unknown')[:60]
                    score = url.get('threat_score', 0)
                    lines.append(f"â”‚  â”œâ”€ {ioc}...")
                    lines.append(f"â”‚  â”‚   Score: {score}/100 â”‚ ğŸš¨ MALICIOUS")
                
                for url in sus_urls[:2]:
                    ioc = url.get('ioc', 'Unknown')[:60]
                    score = url.get('threat_score', 0)
                    lines.append(f"â”‚  â”œâ”€ {ioc}...")
                    lines.append(f"â”‚  â”‚   Score: {score}/100 â”‚ âš ï¸ SUSPICIOUS")
                
                # Show clean URLs count
                clean_urls = len(urls) - len(mal_urls) - len(sus_urls)
                if clean_urls > 0:
                    lines.append(f"â”‚  â””â”€ {clean_urls} URL(s) analyzed as clean")
                lines.append("â”‚")
            
            # Domains
            if domains:
                mal_domains = [d for d in domains if d.get('verdict') == 'MALICIOUS']
                sus_domains = [d for d in domains if d.get('verdict') == 'SUSPICIOUS']
                lines.append(f"â”‚  DOMAINS ({len(domains)} investigated)")
                
                for domain in mal_domains[:3]:
                    ioc = domain.get('ioc', 'Unknown')
                    score = domain.get('threat_score', 0)
                    lines.append(f"â”‚  â”œâ”€ {ioc}")
                    lines.append(f"â”‚  â”‚   Score: {score}/100 â”‚ ğŸš¨ MALICIOUS")
                
                for domain in sus_domains[:2]:
                    ioc = domain.get('ioc', 'Unknown')
                    score = domain.get('threat_score', 0)
                    lines.append(f"â”‚  â”œâ”€ {ioc}")
                    lines.append(f"â”‚  â”‚   Score: {score}/100 â”‚ âš ï¸ SUSPICIOUS")
                
                clean_domains = len(domains) - len(mal_domains) - len(sus_domains)
                if clean_domains > 0:
                    lines.append(f"â”‚  â””â”€ {clean_domains} domain(s) analyzed as clean")
                lines.append("â”‚")
            
            # IPs
            if ips:
                mal_ips = [i for i in ips if i.get('verdict') == 'MALICIOUS']
                if mal_ips:
                    lines.append(f"â”‚  IP ADDRESSES ({len(mal_ips)} malicious)")
                    for ip in mal_ips[:3]:
                        ioc = ip.get('ioc', 'Unknown')
                        score = ip.get('threat_score', 0)
                        lines.append(f"â”‚  â”œâ”€ {ioc} â”‚ Score: {score}/100 â”‚ ğŸš¨ MALICIOUS")
            
            lines.append("â”‚")
            lines.append(f"â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            lines.append(f"â”‚  â”‚ IOC SUMMARY                                 â”‚")
            lines.append(f"â”‚  â”‚ Total: {total} â”‚ Malicious: {malicious} â”‚ Suspicious: {suspicious}   â”‚")
            lines.append(f"â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        else:
            lines.append("â”Œâ”€ IOC ANALYSIS SUMMARY")
            lines.append("â”‚  â„¹ï¸  No IOCs found in email")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== SECTION 7: RECOMMENDATIONS ====================
        lines.append(cls.SECTION_SEP)
        lines.append(" SECTION 7: RECOMMENDATIONS & RESPONSE ACTIONS")
        lines.append(cls.SECTION_SEP)
        lines.append("")
        
        llm_analysis = result.get('llm_analysis', {})
        recommendations = llm_analysis.get('recommendations', [])
        
        if composite_score >= 60:
            lines.append("â”Œâ”€ IMMEDIATE ACTIONS (P1 - Critical)")
            lines.append("â”‚")
            lines.append("â”‚  1. BLOCK sender domain at email gateway")
            if email_data.get('from_domain'):
                lines.append(f"â”‚     â””â”€ {email_data.get('from_domain')}")
            lines.append("â”‚")
            lines.append("â”‚  2. QUARANTINE email in all mailboxes")
            lines.append("â”‚     â””â”€ Search: Subject contains suspicious keywords")
            lines.append("â”‚")
            lines.append("â”‚  3. ALERT Security Operations Center")
            lines.append("â”‚     â””â”€ Priority: P1 - Critical")
            lines.append("â”‚")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        if recommendations:
            lines.append("â”Œâ”€ AI-GENERATED RECOMMENDATIONS")
            lines.append("â”‚")
            for i, rec in enumerate(recommendations, 1):
                lines.append(f"â”‚  {i}. {rec}")
            lines.append("â”‚")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== SECTION 8: DETECTION RULES ====================
        detection_rules = result.get('detection_rules', {})
        if detection_rules:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 8: DETECTION RULES")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            if detection_rules.get('kql'):
                lines.append("â”Œâ”€ KQL (Microsoft Defender / Sentinel)")
                for line in detection_rules['kql'].split('\n')[:12]:
                    lines.append(f"â”‚  {line}")
                if len(detection_rules['kql'].split('\n')) > 12:
                    lines.append("â”‚  ... (truncated)")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            if detection_rules.get('sigma'):
                lines.append("â”Œâ”€ SIGMA Rule")
                for line in detection_rules['sigma'].split('\n')[:15]:
                    lines.append(f"â”‚  {line}")
                if len(detection_rules['sigma'].split('\n')) > 15:
                    lines.append("â”‚  ... (truncated)")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            if detection_rules.get('spl'):
                lines.append("â”Œâ”€ SPL (Splunk)")
                for line in detection_rules['spl'].split('\n')[:10]:
                    lines.append(f"â”‚  {line}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
        
        # ==================== SECTION 9: FORENSICS ANALYSIS ====================
        forensics = result.get('forensics', {})
        raw_output = result.get('raw_output', {})
        raw_forensics = raw_output.get('email_analysis', {}).get('forensics', {})
        
        if forensics or raw_forensics:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 9: DFIR-GRADE FORENSICS")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            forensics_score = forensics.get('forensics_score', raw_forensics.get('forensics_score', 0))
            lines.append(f"â”Œâ”€ FORENSICS SCORE: {forensics_score}/100")
            lines.append("â”‚")
            
            # Timeline
            timeline = forensics.get('timeline', raw_forensics.get('timeline', []))
            if timeline:
                lines.append("â”‚  EMAIL TIMELINE:")
                for entry in timeline[:5]:
                    lines.append(f"â”‚    {entry.get('time', 'N/A')} - {entry.get('event', 'N/A')}")
            
            # Relay analysis
            relay = forensics.get('relay_analysis', raw_forensics.get('relay_analysis', {}))
            if relay:
                lines.append("â”‚")
                lines.append("â”‚  RELAY ANALYSIS:")
                lines.append(f"â”‚    Total Hops: {relay.get('total_hops', 0)}")
                
                suspicious_hops = relay.get('suspicious_hops', [])
                if suspicious_hops:
                    lines.append("â”‚    âš ï¸ SUSPICIOUS HOPS:")
                    for hop in suspicious_hops[:3]:
                        lines.append(f"â”‚      â€¢ {hop}")
                
                time_anomalies = relay.get('time_anomalies', [])
                if time_anomalies:
                    lines.append("â”‚    âš ï¸ TIME ANOMALIES:")
                    for anomaly in time_anomalies[:3]:
                        lines.append(f"â”‚      â€¢ {anomaly}")
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== SECTION 10: RAW HEADER DATA ====================
        raw_headers = raw_output.get('email_analysis', {}).get('headers', {})
        if raw_headers:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 10: RAW HEADER DATA")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            lines.append("â”Œâ”€ RECEIVED CHAIN (Full)")
            received_chain = raw_headers.get('received_chain', [])
            for i, hop in enumerate(received_chain[:10], 1):
                lines.append(f"â”‚  Hop {i}: {str(hop)[:70]}")
            if len(received_chain) > 10:
                lines.append(f"â”‚  ... and {len(received_chain) - 10} more hops")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
            
            x_headers = raw_headers.get('x_headers', {})
            if x_headers:
                lines.append("â”Œâ”€ X-HEADERS")
                for header, value in list(x_headers.items())[:15]:
                    lines.append(f"â”‚  {header}: {str(value)[:60]}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
        
        # ==================== SECTION 11: AUTHENTICATION RAW DATA ====================
        raw_auth = raw_output.get('email_analysis', {}).get('authentication', {})
        if raw_auth:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 11: AUTHENTICATION RAW DATA")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            lines.append("â”Œâ”€ SPF RECORD")
            spf = raw_auth.get('spf', {})
            lines.append(f"â”‚  Result: {spf.get('result', 'none')}")
            lines.append(f"â”‚  Record: {spf.get('raw_record', 'N/A')}")
            lines.append(f"â”‚  Check IP: {spf.get('check_ip', 'N/A')}")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
            
            lines.append("â”Œâ”€ DKIM SIGNATURE")
            dkim = raw_auth.get('dkim', {})
            lines.append(f"â”‚  Result: {dkim.get('result', 'none')}")
            lines.append(f"â”‚  Selector: {dkim.get('selector', 'N/A')}")
            lines.append(f"â”‚  Domain: {dkim.get('domain', 'N/A')}")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
            
            lines.append("â”Œâ”€ DMARC POLICY")
            dmarc = raw_auth.get('dmarc', {})
            lines.append(f"â”‚  Result: {dmarc.get('result', 'none')}")
            lines.append(f"â”‚  Policy: {dmarc.get('policy', 'N/A')}")
            lines.append(f"â”‚  Record: {dmarc.get('raw_record', 'N/A')}")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== SECTION 12: SCORING BREAKDOWN ====================
      
        lines.append(cls.SECTION_SEP)
        lines.append(" SECTION 12: SCORING BREAKDOWN")
        lines.append(cls.SECTION_SEP)
        lines.append("")
        
        # Get values - prefer result-level values over scoring_details
        scoring = raw_output.get('scoring_details', {})
        final_score = result.get('composite_score', scoring.get('composite_score', 0))
        final_verdict = result.get('verdict', scoring.get('verdict', 'UNKNOWN'))
        base_score = result.get('base_phishing_score', scoring.get('base_score', 0))
        forensics_score = result.get('forensics', {}).get('forensics_score', 0)
        
        lines.append("â”Œâ”€ COMPOSITE SCORE CALCULATION")
        lines.append(f"â”‚  Final Score: {final_score}/100")
        lines.append(f"â”‚  Verdict: {final_verdict}")
        lines.append("â”‚")
        lines.append(f"â”‚  Base Phishing Score: {base_score}/100")
        lines.append(f"â”‚  Forensics Risk Score: {forensics_score}/100")
        lines.append("â”‚")
        
        breakdown = scoring.get('breakdown', {})
        if breakdown:
            lines.append("â”‚  BREAKDOWN:")
            for component, score in breakdown.items():
                bar_len = int(min(int(score) if isinstance(score, (int, float)) else 0, 100) / 5)
                bar = "â–ˆ" * bar_len + "â–‘" * (20 - bar_len)
                lines.append(f"â”‚  {component:25s} [{bar}] {score}")
        
        lines.append("â””" + "â”€" * 77)
        lines.append("")
        
        # ==================== SECTION 13: PIPELINE LOG ====================
        pipeline_steps = raw_output.get('pipeline_steps', [])
        if pipeline_steps:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 13: ANALYSIS PIPELINE LOG")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            lines.append("â”Œâ”€ AUTOMATED ANALYSIS STEPS")
            for step in pipeline_steps:
                status_icon = "âœ…" if step.get('status') == 'completed' else "âŒ" if step.get('status') == 'failed' else "â³"
                step_name = step.get('step', step.get('name', step.get('details', 'unknown')))
                lines.append(f"â”‚  {status_icon} [{step.get('phase', 'unknown'):12s}] {step_name}")
            lines.append(f"â”‚")
            lines.append(f"â”‚  Total Steps: {len(pipeline_steps)}")
            lines.append(f"â”‚  Completed: {sum(1 for s in pipeline_steps if s.get('status') == 'completed')}")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== FOOTER ====================
        lines.append(cls.SECTION_SEP)
        lines.append("")
        lines.append(f"Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}")
        lines.append("Blue Team Assistant Version: 1.0.0")
        lines.append("")
        
        return '\n'.join(lines)
    
    @classmethod
    def format_file_report(cls, result: Dict, file_path: str) -> str:
        """
        Format comprehensive malware analysis report.
        """
        lines = []
        
        from pathlib import Path
        filename = Path(file_path).name
        
        # ==================== HEADER ====================
        lines.append(cls.BOX_TOP)
        lines.append(f"{cls.BOX_MID}  ğŸ”¬ MALWARE ANALYSIS REPORT{' ' * 48}{cls.BOX_MID}")
        lines.append(f"{cls.BOX_MID}  File: {filename[:65]}{' ' * max(0, 65 - len(filename))}{cls.BOX_MID}")
        lines.append(cls.BOX_BOT)
        lines.append("")
        
        # ==================== VERDICT BOX ====================
        verdict = result.get('verdict', 'UNKNOWN')
        composite_score = result.get('composite_score', 0)
        hash_score = result.get('hash_score', 0)
        
        verdict_emoji = {'MALICIOUS': 'ğŸ¦ ', 'SUSPICIOUS': 'âš ï¸', 'CLEAN': 'âœ…', 'UNKNOWN': 'â“'}
        risk_level = "CRITICAL" if composite_score >= 85 else "HIGH" if composite_score >= 60 else "MEDIUM" if composite_score >= 30 else "LOW"
        
        lines.append(cls.BOX_SINGLE_TOP)
        lines.append(f"{cls.BOX_SINGLE_MID}  {verdict_emoji.get(verdict, '')} VERDICT: {verdict}{' ' * (60 - len(verdict))}{cls.BOX_SINGLE_MID}")
        lines.append(f"{cls.BOX_SINGLE_MID}  Composite Score: {composite_score}/100 ({risk_level}){' ' * (48 - len(str(composite_score)) - len(risk_level))}{cls.BOX_SINGLE_MID}")
        lines.append(f"{cls.BOX_SINGLE_MID}  Hash Score: {hash_score}/100{' ' * (57 - len(str(hash_score)))}{cls.BOX_SINGLE_MID}")
        
        # Malware family if detected
        yara_analysis = result.get('yara_analysis', {})
        interpretation = yara_analysis.get('interpretation', {})
        malware_families = interpretation.get('malware_families', [])
        if malware_families:
            family_str = ', '.join(malware_families[:2])
            lines.append(f"{cls.BOX_SINGLE_MID}  Malware Family: {family_str}{' ' * max(0, 54 - len(family_str))}{cls.BOX_SINGLE_MID}")
        
        lines.append(cls.BOX_SINGLE_BOT)
        lines.append("")
        
        # ==================== SECTION 1: FILE INFO ====================
        lines.append(cls.SECTION_SEP)
        lines.append(" SECTION 1: FILE INFORMATION")
        lines.append(cls.SECTION_SEP)
        lines.append("")
        
        file_info = result.get('file_info', {})
        hashes = result.get('hashes', {})
        
        lines.append(f"  File Name    : {file_info.get('name', filename)}")
        lines.append(f"  File Size    : {file_info.get('size', 0):,} bytes ({file_info.get('size_mb', 0)} MB)")
        lines.append(f"  File Type    : {file_info.get('extension', 'Unknown')}")
        lines.append("")
        lines.append("  HASHES:")
        lines.append(f"  â”œâ”€ MD5       : {hashes.get('md5', 'Unknown')}")
        lines.append(f"  â”œâ”€ SHA1      : {hashes.get('sha1', 'Unknown')}")
        lines.append(f"  â””â”€ SHA256    : {hashes.get('sha256', 'Unknown')}")
        lines.append("")
        
        # ==================== SECTION 2: STATIC ANALYSIS ====================
        static = result.get('static_analysis', {})
        file_type = str(result.get('file_type', static.get('file_type', 'unknown'))).lower()
        
        # -------------------- SCRIPT ANALYSIS --------------------
        if file_type == 'script' or static.get('script_type'):
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 2: SCRIPT STATIC ANALYSIS")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            # Script Info
            lines.append("â”Œâ”€ SCRIPT INFORMATION")
            lines.append("â”‚")
            lines.append(f"â”‚  Script Type       : {static.get('script_type', 'Unknown').upper()}")
            lines.append(f"â”‚  Size (bytes)      : {static.get('size', static.get('file_size', 0)):,}")
            lines.append(f"â”‚  Threat Score      : {static.get('threat_score', 0)}/100")
            lines.append(f"â”‚  Verdict           : {static.get('verdict', 'Unknown')}")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
            
            # Threat Indicators
            threat_indicators = static.get('threat_indicators', [])
            if threat_indicators:
                lines.append(f"â”Œâ”€ THREAT INDICATORS ({len(threat_indicators)} found)")
                lines.append("â”‚")
                for indicator in threat_indicators[:10]:
                    icon = "ğŸš¨" if any(x in indicator.lower() for x in ['execution', 'credential', 'obfuscated']) else "âš ï¸"
                    lines.append(f"â”‚  {icon} {indicator}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Suspicious Patterns
            patterns = static.get('suspicious_patterns', {})
            categories = patterns.get('categories', {})
            if categories:
                total_matches = patterns.get('total_matches', sum(c.get('count', 0) for c in categories.values()))
                lines.append(f"â”Œâ”€ SUSPICIOUS PATTERNS ({total_matches} matches)")
                lines.append("â”‚")
                
                # Sort by count
                sorted_cats = sorted(categories.items(), key=lambda x: x[1].get('count', 0), reverse=True)
                for category, data in sorted_cats:
                    count = data.get('count', 0)
                    samples = data.get('samples', [])
                    
                    # Risk level icons
                    if category in ['execution', 'download', 'credential', 'evasion']:
                        icon = "ğŸ”´"
                    elif category in ['persistence', 'encoding', 'network']:
                        icon = "ğŸŸ "
                    else:
                        icon = "ğŸŸ¡"
                    
                    lines.append(f"â”‚  {icon} {category.upper()}: {count} patterns")
                    for sample in samples[:3]:
                        lines.append(f"â”‚     â””â”€ {sample[:60]}")
                
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Obfuscation Detection
            obfuscation = static.get('obfuscation', {})
            if obfuscation.get('likely_obfuscated'):
                lines.append("â”Œâ”€ OBFUSCATION DETECTED ğŸš¨")
                lines.append("â”‚")
                lines.append(f"â”‚  Confidence: {obfuscation.get('confidence', 0)}%")
                techniques = obfuscation.get('techniques', [])
                if techniques:
                    lines.append(f"â”‚  Techniques: {', '.join(techniques[:5])}")
                indicators = obfuscation.get('indicators', [])
                for ind in indicators[:5]:
                    lines.append(f"â”‚  â”œâ”€ {ind}")
                lines.append("â”‚")
                lines.append("â”‚  âš ï¸  Obfuscation is commonly used to evade detection")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Encoded Content
            encoded = static.get('encoded_content', [])
            if encoded:
                lines.append(f"â”Œâ”€ ENCODED CONTENT ({len(encoded)} blocks)")
                lines.append("â”‚")
                for enc in encoded[:5]:
                    enc_type = enc.get('type', 'unknown')
                    original = enc.get('encoded', '')[:50]
                    decoded = enc.get('decoded', '')[:50]
                    lines.append(f"â”‚  [{enc_type.upper()}]")
                    lines.append(f"â”‚  â”œâ”€ Encoded : {original}...")
                    if decoded:
                        lines.append(f"â”‚  â””â”€ Decoded : {decoded}...")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Network Indicators
            network = static.get('network_indicators', [])
            if network:
                lines.append(f"â”Œâ”€ NETWORK INDICATORS ({len(network)} found)")
                lines.append("â”‚")
                for net in network[:10]:
                    lines.append(f"â”‚  ğŸŒ {net}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # File Indicators
            file_ind = static.get('file_indicators', [])
            if file_ind:
                lines.append(f"â”Œâ”€ FILE SYSTEM INDICATORS ({len(file_ind)} found)")
                lines.append("â”‚")
                for f in file_ind[:10]:
                    lines.append(f"â”‚  ğŸ“ {f}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Registry Indicators
            registry = static.get('registry_indicators', [])
            if registry:
                lines.append(f"â”Œâ”€ REGISTRY INDICATORS ({len(registry)} found)")
                lines.append("â”‚")
                for reg in registry[:10]:
                    lines.append(f"â”‚  ğŸ”‘ {reg}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # IOCs from Script
            iocs = static.get('iocs', {})
            if any(iocs.values()):
                total_iocs = sum(len(v) for v in iocs.values() if isinstance(v, list))
                lines.append(f"â”Œâ”€ EXTRACTED IOCs ({total_iocs} found)")
                lines.append("â”‚")
                if iocs.get('urls'):
                    lines.append(f"â”‚  URLs ({len(iocs['urls'])}):")
                    for url in iocs['urls'][:5]:
                        lines.append(f"â”‚  â”œâ”€ {url[:70]}")
                if iocs.get('ipv4'):
                    lines.append(f"â”‚  IPs ({len(iocs['ipv4'])}):")
                    for ip in iocs['ipv4'][:5]:
                        lines.append(f"â”‚  â”œâ”€ {ip}")
                if iocs.get('domains'):
                    lines.append(f"â”‚  Domains ({len(iocs['domains'])}):")
                    for domain in iocs['domains'][:5]:
                        lines.append(f"â”‚  â”œâ”€ {domain}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Analysis Tools Used
            tools = static.get('analysis_tools', [])
            if tools:
                lines.append(f"â”Œâ”€ ANALYSIS TOOLS USED")
                lines.append("â”‚")
                lines.append(f"â”‚  {', '.join(tools)}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
          
            # Get entropy from multiple possible locations
            entropy_analysis = result.get('entropy_analysis', {})
            if not entropy_analysis:
                raw_output = result.get('raw_output', {})
                entropy_analysis = raw_output.get('file_analysis', {}).get('tool_outputs', {}).get('entropy', {})
            
            if entropy_analysis:
                # Handle both structures: with file_entropy wrapper or direct
                if 'file_entropy' in entropy_analysis:
                    file_entropy = entropy_analysis['file_entropy']
                    overall_entropy = file_entropy.get('overall_entropy', 0)
                    interpretation = file_entropy.get('interpretation', {})
                else:
                    # Direct structure from tool_outputs
                    overall_entropy = entropy_analysis.get('overall_entropy', 0)
                    interpretation = entropy_analysis.get('interpretation', {})
                
                category = interpretation.get('category', 'unknown')
                description = interpretation.get('description', '')
                
                lines.append("â”Œâ”€ ENTROPY ANALYSIS")
                lines.append("â”‚")
                lines.append(f"â”‚  Overall File Entropy: {overall_entropy:.2f} / 8.00")
                lines.append("â”‚")
                
                # Visual bar
                bar_filled = int(overall_entropy / 8.0 * 50)
                bar = "â–ˆ" * bar_filled + "â–‘" * (50 - bar_filled)
                pct = int(overall_entropy / 8.0 * 100)
                lines.append(f"â”‚  â”Œ{'â”€' * 54}â”")
                lines.append(f"â”‚  â”‚ {bar} {pct:3d}% â”‚")
                lines.append(f"â”‚  â””{'â”€' * 54}â”˜")
                lines.append("â”‚")
                lines.append(f"â”‚  Classification: {category.upper()}")
                if description:
                    lines.append(f"â”‚  Interpretation: {description}")
                lines.append("â”‚")
                
                # Chunk analysis if available
                chunk_analysis = entropy_analysis.get('chunk_analysis', {})
                if chunk_analysis:
                    lines.append(f"â”‚  Chunk Analysis:")
                    lines.append(f"â”‚    Average: {chunk_analysis.get('average', 0):.2f}")
                    lines.append(f"â”‚    Max: {chunk_analysis.get('max', 0):.2f}")
                    lines.append(f"â”‚    Min: {chunk_analysis.get('min', 0):.2f}")
                    lines.append("â”‚")
                
                if overall_entropy > 7.0:
                    lines.append("â”‚  ğŸš¨ HIGH ENTROPY - Likely PACKED or ENCRYPTED")
                elif overall_entropy > 6.5:
                    lines.append("â”‚  âš ï¸  ELEVATED ENTROPY - May contain compressed/encoded data")
                elif overall_entropy < 4.0:
                    lines.append("â”‚  â„¹ï¸  LOW ENTROPY - Plain text or low complexity data")
                
                lines.append("â””" + "â”€" * 77)
                lines.append("")
        
        # -------------------- PE ANALYSIS --------------------
        elif file_type == 'pe' or str(static.get('file_type', '')).lower() == 'pe':
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 2: PE STATIC ANALYSIS")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
          
            pe_analysis = static.get('pe_analysis', {})
            headers = pe_analysis.get('headers', {})
            
            # Map machine code to architecture
            machine_map = {
                '0x14c': 'x86 (32-bit)',
                '0x8664': 'x64 (64-bit)',
                '0x1c0': 'ARM',
                '0xaa64': 'ARM64',
            }
            machine = headers.get('machine', 'Unknown')
            architecture = machine_map.get(machine, machine)
            
            # Determine PE type from characteristics
            characteristics = headers.get('characteristics', '')
            if '0x2000' in str(characteristics) or headers.get('is_dll'):
                pe_type = 'DLL'
            elif '0x2' in str(characteristics):
                pe_type = 'EXE'
            else:
                pe_type = 'EXE'  # Default
            
            # Format timestamp
            timestamp = headers.get('timestamp', 0)
            if timestamp:
                from datetime import datetime
                try:
                    compile_time = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')
                except:
                    compile_time = str(timestamp)
            else:
                compile_time = 'Unknown'
            
            # Subsystem mapping
            subsystem_map = {
                1: 'Native', 2: 'Windows GUI', 3: 'Windows Console',
                5: 'OS/2 Console', 7: 'POSIX Console', 9: 'Windows CE',
                10: 'EFI Application', 14: 'Xbox'
            }
            subsystem = headers.get('subsystem', 0)
            subsystem_str = subsystem_map.get(subsystem, f'Unknown ({subsystem})')
            
            entry_point = headers.get('entry_point', 'Unknown')
            if entry_point != 'Unknown':
                entry_point = f"0x{entry_point:X}" if isinstance(entry_point, int) else entry_point
            
            lines.append("â”Œâ”€ PE HEADER INFORMATION")
            lines.append("â”‚")
            lines.append(f"â”‚  Architecture      : {architecture}")
            lines.append(f"â”‚  PE Type           : {pe_type}")
            lines.append(f"â”‚  Compile Time      : {compile_time}")
            lines.append(f"â”‚  Entry Point       : {entry_point}")
            lines.append(f"â”‚  Subsystem         : {subsystem_str}")
            lines.append("â”‚")
            
            # Security features
            aslr = "âœ…" if headers.get('aslr') else "âŒ"
            dep = "âœ…" if headers.get('dep') else "âŒ"
            cfg = "âœ…" if headers.get('cfg') else "âŒ"
            lines.append(f"â”‚  ASLR: {aslr} | DEP: {dep} | CFG: {cfg}")
            lines.append("â”‚")
            
            sig = static.get('signature', {})
            sig_status = "âœ… Signed" if sig.get('signed') else "âŒ Unsigned"
            lines.append(f"â”‚  Digital Signature : {sig_status}")
            if sig.get('signed') and sig.get('signer'):
                lines.append(f"â”‚    â””â”€ Signer: {sig.get('signer')}")
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
            
            # Entropy - v1.0.0: Get from result, not static
            entropy_analysis = result.get('entropy_analysis', {})
            # Fallback to raw_output if not in result
            if not entropy_analysis:
                raw_output = result.get('raw_output', {})
                entropy_analysis = raw_output.get('file_analysis', {}).get('tool_outputs', {}).get('entropy', {})
            
            if entropy_analysis:
                # Handle both structures: with file_entropy wrapper or direct
                if 'file_entropy' in entropy_analysis:
                    file_entropy = entropy_analysis['file_entropy']
                    overall_entropy = file_entropy.get('overall_entropy', 0)
                    interpretation = file_entropy.get('interpretation', {})
                else:
                    # Direct structure from tool_outputs
                    overall_entropy = entropy_analysis.get('overall_entropy', 0)
                    interpretation = entropy_analysis.get('interpretation', {})
                
                category = interpretation.get('category', 'unknown')
                description = interpretation.get('description', '')
                
                lines.append("â”Œâ”€ ENTROPY ANALYSIS")
                lines.append("â”‚")
                lines.append(f"â”‚  Overall File Entropy: {overall_entropy:.2f} / 8.00")
                lines.append("â”‚")
                
                # Visual bar
                bar_filled = int(overall_entropy / 8.0 * 50)
                bar = "â–ˆ" * bar_filled + "â–‘" * (50 - bar_filled)
                pct = int(overall_entropy / 8.0 * 100)
                lines.append(f"â”‚  â”Œ{'â”€' * 54}â”")
                lines.append(f"â”‚  â”‚ {bar} {pct:3d}% â”‚")
                lines.append(f"â”‚  â””{'â”€' * 54}â”˜")
                lines.append("â”‚")
                lines.append(f"â”‚  Classification: {category.upper()}")
                if description:
                    lines.append(f"â”‚  Interpretation: {description}")
                lines.append("â”‚")
                
                if overall_entropy > 7.0:
                    lines.append("â”‚  ğŸš¨ HIGH ENTROPY - Likely PACKED or ENCRYPTED")
                
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Sections
            sections = static.get('sections', [])
            if sections:
                lines.append(f"â”Œâ”€ SECTION ANALYSIS ({len(sections)} sections)")
                lines.append("â”‚")
                lines.append("â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
                lines.append("â”‚  â”‚ Section â”‚ V.Size    â”‚ Raw Size  â”‚ Entropy â”‚ Characteristics          â”‚")
                lines.append("â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
                
                for section in sections[:10]:
                    name = section.get('name', 'Unknown')[:8]
                    vsize = section.get('virtual_size', 0)
                    rsize = section.get('raw_size', 0)
                    entropy = section.get('entropy', 0)
                    chars = section.get('characteristics', [])
                    suspicious = section.get('suspicious', False)
                    
                    char_str = '/'.join(chars[:3]) if chars else '-'
                    char_str = char_str[:24]
                    
                    flag = "ğŸš¨" if suspicious else "  "
                    
                    lines.append(f"â”‚  â”‚{flag}{name:8s}â”‚ {vsize:9,} â”‚ {rsize:9,} â”‚ {entropy:7.2f} â”‚ {char_str:24s}â”‚")
                    
                    if suspicious and section.get('suspicion_reason'):
                        lines.append(f"â”‚  â”‚         â”” âš ï¸  {section.get('suspicion_reason')[:50]}")
                
                lines.append("â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Packer
            packer = static.get('packer_detection', {})
            if packer.get('packed'):
                lines.append("â”Œâ”€ PACKER DETECTION")
                lines.append("â”‚")
                lines.append(f"â”‚  ğŸš¨ PACKER DETECTED: {packer.get('packer', 'Unknown')}")
                lines.append(f"â”‚  Confidence: {packer.get('confidence', 'Unknown').upper()}")
                lines.append("â”‚")
                indicators = packer.get('indicators', [])
                if indicators:
                    lines.append("â”‚  INDICATORS:")
                    for ind in indicators[:5]:
                        lines.append(f"â”‚  â”œâ”€ {ind}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Suspicious Imports
            imports = static.get('imports', [])
            suspicious_imports = [imp for imp in imports if imp.get('suspicious_count', 0) > 0]
            
            if suspicious_imports:
                total_sus = sum(imp.get('suspicious_count', 0) for imp in imports)
                lines.append(f"â”Œâ”€ IMPORT ANALYSIS ({total_sus} suspicious APIs)")
                lines.append("â”‚")
                
                for imp in suspicious_imports[:6]:
                    dll = imp.get('dll', 'Unknown')
                    sus_apis = imp.get('suspicious_apis', [])
                    lines.append(f"â”‚  {dll}")
                    for api in sus_apis[:4]:
                        lines.append(f"â”‚  â”œâ”€ ğŸš¨ {api}")
                    if len(sus_apis) > 4:
                        lines.append(f"â”‚  â””â”€ ... {len(sus_apis) - 4} more")
                
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Anti-Analysis
            anti_analysis = static.get('anti_analysis', [])
            if anti_analysis:
                lines.append(f"â”Œâ”€ ANTI-ANALYSIS TECHNIQUES ({len(anti_analysis)} detected)")
                lines.append("â”‚")
                for technique in anti_analysis[:8]:
                    lines.append(f"â”‚  ğŸš¨ {technique}")
                lines.append("â”‚")
                lines.append("â”‚  âš ï¸  Multiple anti-analysis techniques indicate malicious intent")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
        
        # ==================== SECTION 2.5: PROFESSIONAL TOOL ANALYSIS  ====================
        lines.extend(cls._format_professional_tools_section(result))
        
        # ==================== SECTION 3: STRING ANALYSIS ====================
        string_analysis = result.get('string_analysis', {})
        if string_analysis.get('total_strings', 0) > 0:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 3: STRING ANALYSIS")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            lines.append(f"â”Œâ”€ STRING STATISTICS")
            lines.append(f"â”‚  Total Strings    : {string_analysis.get('total_strings', 0):,}")
            lines.append(f"â”‚  ASCII Strings    : {string_analysis.get('ascii_strings', 0):,}")
            lines.append(f"â”‚  Unicode Strings  : {string_analysis.get('unicode_strings', 0):,}")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
            
            # Suspicious Categories
            categories = string_analysis.get('suspicious_categories', {})
            if categories:
                lines.append("â”Œâ”€ SUSPICIOUS STRING CATEGORIES")
                for cat, strings in list(categories.items())[:6]:
                    if strings:
                        count = len(strings) if isinstance(strings, list) else strings
                        lines.append(f"â”‚  {cat}: {count} strings")
                        if isinstance(strings, list):
                            for s in strings[:3]:
                                lines.append(f"â”‚    â€¢ {s[:60]}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Registry Keys
            registry_keys = string_analysis.get('registry_keys', [])
            if registry_keys:
                lines.append("â”Œâ”€ REGISTRY KEYS")
                for key in registry_keys[:5]:
                    lines.append(f"â”‚  â€¢ {key[:70]}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Interesting Strings
            interesting = string_analysis.get('interesting_strings', [])
            if interesting:
                lines.append("â”Œâ”€ INTERESTING STRINGS (Top 10)")
                for s in interesting[:10]:
                    lines.append(f"â”‚  â€¢ {s[:70]}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
        
        # ==================== SECTION 4: YARA ANALYSIS ====================
        yara_analysis = result.get('yara_analysis', {})
        matches = yara_analysis.get('matches', [])
        
        if matches:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 4: YARA ANALYSIS")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            lines.append(f"â”Œâ”€ YARA MATCHES ({len(matches)} rules)")
            
            for match in matches[:5]:
                rule = match.get('rule', 'Unknown')
                severity = match.get('meta', {}).get('severity', 'UNKNOWN')
                description = match.get('meta', {}).get('description', '')
                
                severity_emoji = "ğŸš¨" if severity in ['CRITICAL', 'HIGH'] else "âš ï¸"
                
                lines.append("â”‚")
                lines.append(f"â”‚  RULE: {rule}")
                lines.append(f"â”‚  â”œâ”€ Severity    : {severity_emoji} {severity}")
                if description:
                    lines.append(f"â”‚  â””â”€ Description : {description[:50]}")
            
            lines.append("â”‚")
            
            # Malware families
            if malware_families:
                lines.append("â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
                lines.append(f"â”‚  â”‚ ğŸ¦  MALWARE FAMILY: {', '.join(malware_families[:2]):22s}â”‚")
                lines.append("â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== SECTION 5: SANDBOX ANALYSIS ====================
        sandbox_analysis = result.get('sandbox_analysis', {})
        summary = sandbox_analysis.get('summary', {})
        
        if summary.get('available_reports', 0) > 0:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 5: SANDBOX ANALYSIS")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            # VirusTotal
            vt = sandbox_analysis.get('virustotal_behavior', {})
            if vt and not vt.get('error'):
                lines.append("â”Œâ”€ VirusTotal Behavior")
                if vt.get('found'):
                    lines.append("â”‚  Status: âœ… REPORT FOUND")
                    behaviors = vt.get('behaviors', [])
                    if behaviors:
                        for b in behaviors[:3]:
                            lines.append(f"â”‚  â€¢ {b}")
                    if vt.get('report_url'):
                        lines.append(f"â”‚  ğŸ”— {vt.get('report_url')}")
                else:
                    lines.append("â”‚  Status: âš ï¸ NO REPORT FOUND")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # ANY.RUN
            anyrun = sandbox_analysis.get('anyrun', {})
            if anyrun and not anyrun.get('error'):
                lines.append("â”Œâ”€ ANY.RUN")
                if anyrun.get('found'):
                    lines.append("â”‚  Status: âœ… SUBMISSION FOUND")
                    lines.append(f"â”‚  Verdict: {anyrun.get('verdict', 'Unknown')}")
                    if anyrun.get('malware_family'):
                        lines.append(f"â”‚  Family: {anyrun.get('malware_family')}")
                    if anyrun.get('report_url'):
                        lines.append(f"â”‚  ğŸ”— {anyrun.get('report_url')}")
                else:
                    lines.append("â”‚  Status: âš ï¸ NO SUBMISSION FOUND")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Aggregate behaviors
            behaviors = summary.get('behaviors', [])
            if behaviors:
                lines.append("â”Œâ”€ AGGREGATE BEHAVIORS")
                for b in behaviors[:5]:
                    lines.append(f"â”‚  â€¢ {b}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # MITRE (quick summary in sandbox)
            mitre = summary.get('mitre_techniques', [])
            if mitre:
                lines.append("â”Œâ”€ MITRE ATT&CK Techniques")
                lines.append(f"â”‚  {', '.join(mitre[:8])}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
        
        # ==================== SECTION 4: MITRE ATT&CK MAPPING (v1.0.0) ====================
        mitre_mapping = result.get('mitre_mapping', [])
        # Also check sandbox for MITRE if mitre_mapping is empty
        if not mitre_mapping:
            sandbox = result.get('sandbox_analysis', {})
            sandbox_summary = sandbox.get('summary', {})
            sandbox_mitre = sandbox_summary.get('mitre_techniques', [])
            if sandbox_mitre:
                mitre_mapping = [{'technique_id': t, 'source': 'sandbox'} for t in sandbox_mitre]
        
        if mitre_mapping:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 4: MITRE ATT&CK MAPPING")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            # Group by tactic/category
            tactics = {
                'T1059': ('Execution', 'Command and Scripting Interpreter'),
                'T1059.001': ('Execution', 'PowerShell'),
                'T1027': ('Defense Evasion', 'Obfuscated Files or Information'),
                'T1140': ('Defense Evasion', 'Deobfuscate/Decode Files'),
                'T1547': ('Persistence', 'Boot or Logon Autostart Execution'),
                'T1547.009': ('Persistence', 'Shortcut Modification'),
                'T1053': ('Persistence', 'Scheduled Task/Job'),
                'T1003': ('Credential Access', 'OS Credential Dumping'),
                'T1555': ('Credential Access', 'Credentials from Password Stores'),
                'T1082': ('Discovery', 'System Information Discovery'),
                'T1083': ('Discovery', 'File and Directory Discovery'),
                'T1012': ('Discovery', 'Query Registry'),
                'T1010': ('Discovery', 'Application Window Discovery'),
                'T1105': ('Command and Control', 'Ingress Tool Transfer'),
                'T1071': ('Command and Control', 'Application Layer Protocol'),
                'T1548': ('Privilege Escalation', 'Abuse Elevation Control'),
                'T1134': ('Privilege Escalation', 'Access Token Manipulation'),
                'T1562': ('Defense Evasion', 'Impair Defenses'),
                'T1070': ('Defense Evasion', 'Indicator Removal'),
                'T1112': ('Defense Evasion', 'Modify Registry'),
                'T1222': ('Defense Evasion', 'File and Directory Permissions Modification'),
                'T1560': ('Collection', 'Archive Collected Data'),
                'T1119': ('Collection', 'Automated Collection'),
                'T1115': ('Collection', 'Clipboard Data'),
                'T1041': ('Exfiltration', 'Exfiltration Over C2 Channel'),
                'T1529': ('Impact', 'System Shutdown/Reboot'),
                'T1129': ('Execution', 'Shared Modules'),
                'T1125': ('Collection', 'Video Capture'),
            }
            
            lines.append("â”Œâ”€ DETECTED TECHNIQUES")
            lines.append("â”‚")
            
            seen = set()
            for mapping in mitre_mapping:
                tech_id = mapping.get('technique_id', '')
                if tech_id in seen:
                    continue
                seen.add(tech_id)
                
                tactic_info = tactics.get(tech_id, ('Unknown', 'Unknown Technique'))
                source = mapping.get('source', 'analysis')
                confidence = mapping.get('confidence', 'medium')
                
                conf_icon = "ğŸ”´" if confidence == 'high' else "ğŸŸ¡" if confidence == 'medium' else "âšª"
                lines.append(f"â”‚  {conf_icon} {tech_id}: {tactic_info[1]}")
                lines.append(f"â”‚     â””â”€ Tactic: {tactic_info[0]} | Source: {source}")
            
            lines.append("â”‚")
            lines.append(f"â”‚  Total Techniques: {len(seen)}")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
            
            # MITRE Navigator link
            tech_ids = [m.get('technique_id', '') for m in mitre_mapping if m.get('technique_id')]
            if tech_ids:
                lines.append("â”Œâ”€ MITRE ATT&CK NAVIGATOR")
                lines.append(f"â”‚  Techniques: {', '.join(list(seen)[:15])}")
                lines.append(f"â”‚  ğŸ”— https://mitre-attack.github.io/attack-navigator/")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
        
        # ==================== SECTION 6: DETECTION RULES ====================
        detection_rules = result.get('detection_rules', {})
        if detection_rules:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 6: DETECTION RULES")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            if detection_rules.get('kql'):
                lines.append("â”Œâ”€ KQL (Microsoft Defender / Sentinel)")
                for line in detection_rules['kql'].split('\n')[:12]:
                    lines.append(f"â”‚  {line}")
                if len(detection_rules['kql'].split('\n')) > 12:
                    lines.append("â”‚  ... (truncated)")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            if detection_rules.get('yara'):
                lines.append("â”Œâ”€ YARA Rule")
                for line in detection_rules['yara'].split('\n')[:20]:
                    lines.append(f"â”‚  {line}")
                if len(detection_rules['yara'].split('\n')) > 20:
                    lines.append("â”‚  ... (truncated)")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            if detection_rules.get('sigma'):
                lines.append("â”Œâ”€ SIGMA Rule")
                for line in detection_rules['sigma'].split('\n')[:18]:
                    lines.append(f"â”‚  {line}")
                if len(detection_rules['sigma'].split('\n')) > 18:
                    lines.append("â”‚  ... (truncated)")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            if detection_rules.get('spl'):
                lines.append("â”Œâ”€ SPL (Splunk)")
                for line in detection_rules['spl'].split('\n')[:10]:
                    lines.append(f"â”‚  {line}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
        
        # ==================== SECTION 7: AI ANALYSIS ====================
        llm = result.get('llm_analysis', {})
        if llm and llm.get('analysis'):
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 7: AI-POWERED ANALYSIS")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            lines.append("â”Œâ”€ LLM ANALYSIS")
            for line in llm.get('analysis', '').split('\n')[:15]:
                lines.append(f"â”‚  {line}")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
            
            if llm.get('recommendations'):
                lines.append("â”Œâ”€ AI RECOMMENDATIONS")
                for rec in llm.get('recommendations', [])[:5]:
                    lines.append(f"â”‚  â€¢ {rec}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
        
        # ==================== SECTION 8: IOC ANALYSIS ====================
        ioc_analysis = result.get('ioc_analysis', {})
        if ioc_analysis.get('total_iocs', 0) > 0:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 8: EMBEDDED IOC ANALYSIS")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            lines.append("â”Œâ”€ IOC SUMMARY")
            lines.append(f"â”‚  Total IOCs Found    : {ioc_analysis.get('total_iocs', 0)}")
            lines.append(f"â”‚  Malicious IOCs      : {ioc_analysis.get('malicious_iocs', 0)}")
            lines.append(f"â”‚  Suspicious IOCs     : {ioc_analysis.get('suspicious_iocs', 0)}")
            lines.append("â”‚")
            
            for ioc_result in ioc_analysis.get('results', [])[:5]:
                ioc = ioc_result.get('ioc', 'Unknown')
                ioc_verdict = ioc_result.get('verdict', 'UNKNOWN')
                ioc_score = ioc_result.get('threat_score', 0)
                emoji = "ğŸš¨" if ioc_verdict == "MALICIOUS" else "âš ï¸" if ioc_verdict == "SUSPICIOUS" else "âœ…"
                lines.append(f"â”‚  {emoji} {ioc[:50]}")
                lines.append(f"â”‚     â””â”€ Verdict: {ioc_verdict} | Score: {ioc_score}/100")
            
            if ioc_analysis.get('total_iocs', 0) > 5:
                lines.append(f"â”‚  ... and {ioc_analysis.get('total_iocs', 0) - 5} more IOCs")
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== SECTION 9: STRING ANALYSIS DETAILS ====================
        string_analysis = result.get('string_analysis', {})
        raw_output = result.get('raw_output', {})
        raw_strings = raw_output.get('file_analysis', {}).get('strings', {})
        
        if string_analysis or raw_strings:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 9: STRING ANALYSIS DETAILS")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            lines.append("â”Œâ”€ STRING STATISTICS")
            lines.append(f"â”‚  Total Strings      : {string_analysis.get('total_strings', raw_strings.get('total_count', 0))}")
            lines.append(f"â”‚  ASCII Strings      : {string_analysis.get('ascii_strings', raw_strings.get('ascii_count', 0))}")
            lines.append(f"â”‚  Unicode Strings    : {string_analysis.get('unicode_strings', raw_strings.get('unicode_count', 0))}")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
            
            # URLs found in strings
            urls = raw_strings.get('urls', []) or string_analysis.get('urls', [])
            if urls:
                lines.append("â”Œâ”€ URLS EXTRACTED FROM STRINGS")
                for url in urls[:15]:
                    lines.append(f"â”‚  â€¢ {url}")
                if len(urls) > 15:
                    lines.append(f"â”‚  ... and {len(urls) - 15} more URLs")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # IPs found
            ips = raw_strings.get('ips', []) or string_analysis.get('ips', [])
            if ips:
                lines.append("â”Œâ”€ IP ADDRESSES EXTRACTED")
                for ip in ips[:10]:
                    lines.append(f"â”‚  â€¢ {ip}")
                if len(ips) > 10:
                    lines.append(f"â”‚  ... and {len(ips) - 10} more IPs")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Registry keys
            registry_keys = string_analysis.get('registry_keys', []) or raw_strings.get('registry', [])
            if registry_keys:
                lines.append("â”Œâ”€ REGISTRY KEYS FOUND")
                for reg in registry_keys[:10]:
                    lines.append(f"â”‚  â€¢ {reg}")
                if len(registry_keys) > 10:
                    lines.append(f"â”‚  ... and {len(registry_keys) - 10} more registry keys")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Mutexes
            mutexes = string_analysis.get('mutexes', []) or raw_strings.get('mutexes', [])
            if mutexes:
                lines.append("â”Œâ”€ MUTEXES FOUND")
                for mutex in mutexes[:5]:
                    lines.append(f"â”‚  â€¢ {mutex}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Suspicious string categories
            categories = string_analysis.get('suspicious_categories', {}) or raw_strings.get('categories', {})
            if categories:
                lines.append("â”Œâ”€ SUSPICIOUS STRING CATEGORIES")
                for category, strings in categories.items():
                    if strings:
                        count = len(strings) if isinstance(strings, list) else strings
                        lines.append(f"â”‚  âš ï¸ {category.upper()}: {count} occurrences")
                        if isinstance(strings, list):
                            for s in strings[:3]:
                                lines.append(f"â”‚     â””â”€ {str(s)[:60]}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Interesting strings
            interesting = string_analysis.get('interesting_strings', []) or raw_strings.get('interesting', [])
            if interesting:
                lines.append("â”Œâ”€ INTERESTING STRINGS (Quick Triage)")
                for s in interesting[:20]:
                    lines.append(f"â”‚  â€¢ {str(s)[:70]}")
                if len(interesting) > 20:
                    lines.append(f"â”‚  ... and {len(interesting) - 20} more")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
        
        # ==================== SECTION 10: THREAT INTEL API RESPONSES ====================
        api_responses = raw_output.get('api_responses', {})
        if api_responses:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 10: THREAT INTEL API RESPONSES")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            for source, data in api_responses.items():
                response = data.get('response', {}) if isinstance(data, dict) else data
                status = data.get('status', 'unknown') if isinstance(data, dict) else 'unknown'
                
                emoji = "âœ…" if status == 'success' else "âŒ" if status == 'error' else "âšª"
                lines.append(f"â”Œâ”€ {source.upper()} {emoji}")
                
                if isinstance(response, dict):
                    for key, value in list(response.items())[:8]:
                        if key not in ['error', 'raw']:
                            lines.append(f"â”‚  {key}: {str(value)[:60]}")
                else:
                    lines.append(f"â”‚  Response: {str(response)[:100]}")
                
                lines.append("â””" + "â”€" * 77)
                lines.append("")
        
        # ==================== SECTION 11: SANDBOX ANALYSIS ====================
        sandbox = result.get('sandbox_analysis', {})
        raw_sandbox = raw_output.get('file_analysis', {}).get('sandbox', {})
        
        if sandbox or raw_sandbox:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 11: SANDBOX ANALYSIS")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            sha256 = result.get('hashes', {}).get('sha256', '')
            
            # VirusTotal
            vt = sandbox.get('virustotal_behavior', {}) or raw_sandbox.get('virustotal', {})
            if vt:
                lines.append("â”Œâ”€ VIRUSTOTAL BEHAVIOR ANALYSIS")
                lines.append(f"â”‚  Status: {'âœ… Found' if vt.get('found') else 'âš ï¸ Not Found'}")
                if vt.get('behaviors'):
                    lines.append("â”‚  Behaviors:")
                    for b in vt.get('behaviors', [])[:5]:
                        lines.append(f"â”‚    â€¢ {b}")
                lines.append(f"â”‚  ğŸ”— https://www.virustotal.com/gui/file/{sha256}/behavior")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # ANY.RUN
            anyrun = sandbox.get('anyrun', {}) or raw_sandbox.get('anyrun', {})
            if anyrun:
                lines.append("â”Œâ”€ ANY.RUN ANALYSIS")
                lines.append(f"â”‚  Status: {'âœ… Found' if anyrun.get('found') else 'âš ï¸ Not Found'}")
                if anyrun.get('verdict'):
                    lines.append(f"â”‚  Verdict: {anyrun.get('verdict')}")
                lines.append(f"â”‚  ğŸ”— https://app.any.run/submissions/#filehash:{sha256}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            # Sandbox Links
            lines.append("â”Œâ”€ SANDBOX QUICK LINKS")
            lines.append(f"â”‚  VirusTotal    : https://www.virustotal.com/gui/file/{sha256}")
            lines.append(f"â”‚  Hybrid Analysis: https://www.hybrid-analysis.com/search?query={sha256}")
            lines.append(f"â”‚  ANY.RUN       : https://app.any.run/submissions/#filehash:{sha256}")
            lines.append(f"â”‚  MalwareBazaar : https://bazaar.abuse.ch/sample/{sha256}/")
            lines.append(f"â”‚  Joe Sandbox   : https://www.joesandbox.com/search?q={sha256}")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== SECTION 12: SCORING BREAKDOWN ====================
        scoring = raw_output.get('scoring_details', {})
        if scoring:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 12: SCORING BREAKDOWN")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            lines.append("â”Œâ”€ COMPOSITE SCORE CALCULATION")
            lines.append(f"â”‚  Final Score: {scoring.get('composite_score', result.get('composite_score', 0))}/100")
            lines.append(f"â”‚  Verdict: {scoring.get('verdict', result.get('verdict', 'UNKNOWN'))}")
            lines.append("â”‚")
            
            breakdown = scoring.get('breakdown', {})
            if breakdown:
                lines.append("â”‚  BREAKDOWN:")
                for component, score in breakdown.items():
                    bar_len = int(min(score, 100) / 5)
                    bar = "â–ˆ" * bar_len + "â–‘" * (20 - bar_len)
                    lines.append(f"â”‚  {component:25s} [{bar}] {score}")
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== SECTION 13: PIPELINE EXECUTION LOG ====================
        pipeline_steps = raw_output.get('pipeline_steps', [])
        if pipeline_steps:
            lines.append(cls.SECTION_SEP)
            lines.append(" SECTION 13: ANALYSIS PIPELINE LOG")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            lines.append("â”Œâ”€ AUTOMATED ANALYSIS STEPS")
            for step in pipeline_steps:
                status_icon = "âœ…" if step.get('status') == 'completed' else "âŒ" if step.get('status') == 'failed' else "â³"
                step_name = step.get('step', step.get('name', step.get('details', 'unknown')))
                lines.append(f"â”‚  {status_icon} [{step.get('phase', 'unknown'):12s}] {step_name}")
            lines.append(f"â”‚")
            lines.append(f"â”‚  Total Steps: {len(pipeline_steps)}")
            lines.append(f"â”‚  Completed: {sum(1 for s in pipeline_steps if s.get('status') == 'completed')}")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== FOOTER ====================
        lines.append(cls.SECTION_SEP)
        lines.append("")
        lines.append(f"Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}")
        lines.append("Blue Team Assistant Version: 1.0.0")
        lines.append("")
        
        return '\n'.join(lines)
    
    @classmethod
    def format_ioc_report(cls, result: Dict, ioc: str) -> str:
        """
        Format comprehensive IOC investigation report.
        """
        lines = []
        
        # ==================== HEADER ====================
        lines.append(cls.BOX_TOP)
        lines.append(f"{cls.BOX_MID}  ğŸ” IOC INVESTIGATION REPORT{' ' * 48}{cls.BOX_MID}")
        lines.append(f"{cls.BOX_MID}  IOC: {ioc[:68]}{' ' * max(0, 68 - len(ioc))}{cls.BOX_MID}")
        lines.append(cls.BOX_BOT)
        lines.append("")
        
        # ==================== VERDICT BOX ====================
        verdict = result.get('verdict', 'UNKNOWN')
        threat_score = result.get('threat_score', 0)
        ioc_type = result.get('ioc_type', 'Unknown')
        
        verdict_emoji = {'MALICIOUS': 'ğŸš¨', 'SUSPICIOUS': 'âš ï¸', 'CLEAN': 'âœ…', 'UNKNOWN': 'â“'}
        risk_level = "CRITICAL" if threat_score >= 80 else "HIGH" if threat_score >= 60 else "MEDIUM" if threat_score >= 30 else "LOW"
        
        lines.append(cls.BOX_SINGLE_TOP)
        lines.append(f"{cls.BOX_SINGLE_MID}  {verdict_emoji.get(verdict, '')} VERDICT: {verdict}{' ' * (60 - len(verdict))}{cls.BOX_SINGLE_MID}")
        lines.append(f"{cls.BOX_SINGLE_MID}  Threat Score: {threat_score}/100 ({risk_level}){' ' * (50 - len(str(threat_score)) - len(risk_level))}{cls.BOX_SINGLE_MID}")
        lines.append(f"{cls.BOX_SINGLE_MID}  IOC Type: {ioc_type}{' ' * (60 - len(ioc_type))}{cls.BOX_SINGLE_MID}")
        lines.append(cls.BOX_SINGLE_BOT)
        lines.append("")
        
        # ==================== THREAT INTEL SOURCES ====================
        lines.append(cls.SECTION_SEP)
        lines.append(f" THREAT INTELLIGENCE SOURCES ({result.get('sources_checked', 0)} Checked, {result.get('sources_flagged', 0)} Flagged)")
        lines.append(cls.SECTION_SEP)
        lines.append("")
        
        # Try multiple possible key names for backward compatibility
        sources = (
            result.get('sources', {}) or 
            result.get('threat_intel_results', {}) or 
            result.get('threat_intelligence', {}).get('sources', {})
        )
        
        # Also get sources_checked/flagged with fallback
        sources_checked = (
            result.get('sources_checked', 0) or 
            result.get('threat_intelligence', {}).get('sources_checked', 0)
        )
        sources_flagged = (
            result.get('sources_flagged', 0) or 
            result.get('threat_intelligence', {}).get('sources_flagged', 0)
        )
        
        lines.append("â”Œâ”€ SOURCE RESULTS")
        lines.append("â”‚")
        lines.append("â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        lines.append("â”‚  â”‚ Source           â”‚ Status   â”‚ Details                                 â”‚")
        lines.append("â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        
        if not sources:
            lines.append("â”‚  â”‚ No sources data available                                              â”‚")
        else:
            for source_name, source_data in sources.items():
                if not isinstance(source_data, dict):
                    continue
                    
                status = source_data.get('status', 'âš ')
                
                # Determine status emoji based on various indicators
                is_flagged = (
                    status in ['âœ“', 'âœ“ FLAGGED', 'FLAGGED'] or
                    source_data.get('malicious', False) or
                    source_data.get('flagged', False) or
                    (source_data.get('score', 0) or 0) > 30 or
                    (source_data.get('fraud_score', 0) or 0) > 50 or
                    (source_data.get('confidence', 0) or 0) > 50
                )
                
                is_clean = status == 'âœ—' or source_data.get('clean', False)
                
                if is_flagged:
                    status_str = "ğŸš¨ FLAG"
                elif is_clean:
                    status_str = "âœ… CLEAN"
                elif source_data.get('error'):
                    status_str = "âŒ ERROR"
                else:
                    status_str = "âšª N/A  "
                
                # Get details - comprehensive extraction
                details = ""
                if source_data.get('detections'):
                    details = f"{source_data.get('detections')} detections"
                elif source_data.get('fraud_score'):
                    details = f"Fraud score: {source_data.get('fraud_score')}%"
                elif source_data.get('confidence'):
                    details = f"Confidence: {source_data.get('confidence')}%"
                elif source_data.get('score') and source_data['score'] > 0:
                    details = f"Score: {source_data.get('score')}/100"
                elif source_data.get('threat'):
                    details = f"Threat: {source_data.get('threat')}"
                elif source_data.get('botnet'):
                    details = f"Botnet: {source_data.get('botnet')}"
                elif source_data.get('classification'):
                    details = f"Class: {source_data.get('classification')}"
                elif source_data.get('ports'):
                    ports = source_data.get('ports', [])
                    if isinstance(ports, list):
                        details = f"Ports: {', '.join(map(str, ports[:5]))}"
                elif source_data.get('vulns'):
                    vulns = source_data.get('vulns', [])
                    if isinstance(vulns, list):
                        details = f"{len(vulns)} vulnerabilities"
                elif source_data.get('reports') is not None:
                    details = f"{source_data.get('reports')} reports"
                elif source_data.get('listed'):
                    details = "Listed in blocklist"
                elif source_data.get('error'):
                    details = f"Error: {source_data.get('error')[:30]}"
                elif source_data.get('message'):
                    details = source_data.get('message')[:35]
                
                details = details[:40] if details else "Checked - No findings"
                
                lines.append(f"â”‚  â”‚ {source_name[:16]:16s} â”‚ {status_str:8s} â”‚ {details:40s}â”‚")
        
        lines.append("â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        lines.append("â”‚")
        lines.append(f"â”‚  Summary: {sources_flagged}/{sources_checked} sources flagged this IOC")
        lines.append("â””" + "â”€" * 77)
        lines.append("")
        
        # ==================== LLM ANALYSIS ====================
        llm_analysis = result.get('llm_analysis', {})
        if llm_analysis and llm_analysis.get('analysis'):
            lines.append(cls.SECTION_SEP)
            lines.append(" AI-POWERED ANALYSIS")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            lines.append(llm_analysis.get('analysis', ''))
            lines.append("")
        
        # ==================== RECOMMENDATIONS ====================
        recommendations = llm_analysis.get('recommendations', [])
        if recommendations:
            lines.append(cls.SECTION_SEP)
            lines.append(" RECOMMENDATIONS")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            for i, rec in enumerate(recommendations, 1):
                lines.append(f"  {i}. {rec}")
            lines.append("")
        
        # ==================== DETECTION RULES ====================
        rules = result.get('detection_rules', {})
        if rules:
            lines.append(cls.SECTION_SEP)
            lines.append(" DETECTION RULES")
            lines.append(cls.SECTION_SEP)
            lines.append("")
            
            if rules.get('kql'):
                lines.append("â”Œâ”€ KQL (Microsoft Defender / Sentinel)")
                for line in rules['kql'].split('\n')[:8]:
                    lines.append(f"â”‚  {line}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
            
            if rules.get('sigma'):
                lines.append("â”Œâ”€ SIGMA Rule")
                for line in rules['sigma'].split('\n')[:10]:
                    lines.append(f"â”‚  {line}")
                lines.append("â””" + "â”€" * 77)
                lines.append("")
        
        # ==================== FOOTER ====================
        lines.append(cls.SECTION_SEP)
        lines.append("")
        lines.append(f"Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}")
        lines.append("Blue Team Assistant Version: 1.0.0")
        lines.append("")
        
        return '\n'.join(lines)
    
    @classmethod
    def _format_professional_tools_section(cls, result: Dict) -> List[str]:
        """Format professional tools section."""
        lines = []
        
        # Check if we have any professional tool outputs
        capabilities = result.get('capabilities', {})
        obfuscated_strings = result.get('obfuscated_strings', {}) or result.get('strings', {})
        packer_info = result.get('packer_detection', {})
        embedded_files = result.get('embedded_files', {})
        analysis_tools = result.get('analysis_tools', [])
        
        # Skip if no professional tools were used
        has_capa = capabilities.get('success') or capabilities.get('capabilities')
        has_floss = obfuscated_strings.get('decoded_count', 0) > 0 or obfuscated_strings.get('stack_count', 0) > 0
        has_die = packer_info.get('packers') or packer_info.get('protectors') or packer_info.get('compilers')
        has_binwalk = embedded_files.get('embedded_files') or embedded_files.get('high_entropy_regions')
        
        if not (has_capa or has_floss or has_die or has_binwalk):
            return lines
        
        lines.append(cls.SECTION_SEP)
        lines.append(" SECTION 2.5: PROFESSIONAL TOOL ANALYSIS ")
        lines.append(cls.SECTION_SEP)
        lines.append("")
        
        if analysis_tools:
            lines.append(f"â”Œâ”€ TOOLS USED: {', '.join(analysis_tools)}")
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== CAPA - CAPABILITY DETECTION ====================
        if has_capa:
            cap_list = capabilities.get('capabilities', [])
            lines.append("â”Œâ”€ CAPA - CAPABILITY DETECTION (Mandiant)")
            lines.append(f"â”‚  Total Capabilities: {len(cap_list)}")
            lines.append(f"â”‚  Threat Score: {capabilities.get('threat_score', 0)}/100")
            lines.append("â”‚")
            
            # Group by namespace
            namespaces = {}
            for cap in cap_list:
                if isinstance(cap, dict):
                    ns = cap.get('namespace', 'unknown').split('/')[0]
                    name = cap.get('name', 'unknown')
                else:
                    ns = 'unknown'
                    name = str(cap)
                if ns not in namespaces:
                    namespaces[ns] = []
                namespaces[ns].append(name)
            
            for ns, caps in sorted(namespaces.items(), key=lambda x: len(x[1]), reverse=True)[:5]:
                lines.append(f"â”‚  [{ns.upper()}] ({len(caps)} capabilities)")
                for cap in caps[:3]:
                    lines.append(f"â”‚    â€¢ {cap}")
                if len(caps) > 3:
                    lines.append(f"â”‚    ... and {len(caps)-3} more")
            
            # ATT&CK techniques
            attack_techniques = capabilities.get('attack_techniques', [])
            if attack_techniques:
                lines.append("â”‚")
                lines.append("â”‚  ğŸ¯ ATT&CK Techniques:")
                seen = set()
                for t in attack_techniques[:10]:
                    if isinstance(t, dict) and t.get('id') and t['id'] not in seen:
                        lines.append(f"â”‚    [{t['id']}] {t.get('technique', 'Unknown')}")
                        seen.add(t['id'])
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== FLOSS - OBFUSCATED STRINGS ====================
        if has_floss:
            lines.append("â”Œâ”€ FLOSS - OBFUSCATED STRING ANALYSIS (Mandiant)")
            lines.append(f"â”‚  Static Strings  : {obfuscated_strings.get('static_count', 0)}")
            lines.append(f"â”‚  Decoded Strings : {obfuscated_strings.get('decoded_count', 0)} âš ï¸")
            lines.append(f"â”‚  Stack Strings   : {obfuscated_strings.get('stack_count', 0)}")
            lines.append(f"â”‚  Tight Strings   : {obfuscated_strings.get('tight_count', 0)}")
            lines.append(f"â”‚  Threat Score    : {obfuscated_strings.get('threat_score', 0)}/100")
            
            urls = obfuscated_strings.get('urls', [])
            if urls:
                lines.append("â”‚")
                lines.append("â”‚  ğŸ”— URLs from Decoded Strings:")
                for url in urls[:5]:
                    lines.append(f"â”‚    â€¢ {url[:70]}")
            
            ips = obfuscated_strings.get('ips', [])
            if ips:
                lines.append("â”‚")
                lines.append(f"â”‚  ğŸŒ IPs: {', '.join(ips[:10])}")
            
            suspicious = obfuscated_strings.get('suspicious_strings', [])
            if suspicious:
                lines.append("â”‚")
                lines.append("â”‚  ğŸš¨ Suspicious Decoded Strings:")
                for s in suspicious[:5]:
                    lines.append(f"â”‚    â€¢ {s[:65]}...")
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== DIE - PACKER DETECTION ====================
        if has_die:
            lines.append("â”Œâ”€ DIE - PACKER/COMPILER DETECTION")
            lines.append(f"â”‚  File Type: {packer_info.get('file_type', 'Unknown')}")
            
            compilers = packer_info.get('compilers', [])
            if compilers:
                lines.append(f"â”‚  Compiler : {', '.join(compilers[:3])}")
            
            linkers = packer_info.get('linkers', [])
            if linkers:
                lines.append(f"â”‚  Linker   : {', '.join(linkers[:3])}")
            
            packers = packer_info.get('packers', [])
            if packers:
                lines.append("â”‚")
                lines.append(f"â”‚  ğŸš¨ PACKER: {', '.join(packers)}")
            
            protectors = packer_info.get('protectors', [])
            if protectors:
                lines.append("â”‚")
                lines.append(f"â”‚  ğŸš¨ PROTECTOR: {', '.join(protectors)}")
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        # ==================== BINWALK - EMBEDDED FILES ====================
        if has_binwalk:
            lines.append("â”Œâ”€ BINWALK - EMBEDDED FILE ANALYSIS")
            
            embedded = embedded_files.get('embedded_files', [])
            if embedded:
                lines.append(f"â”‚  Embedded Items: {len(embedded)}")
                for item in embedded[:5]:
                    offset = item.get('offset', 0)
                    desc = item.get('description', 'Unknown')[:60]
                    lines.append(f"â”‚  @ 0x{offset:08X}: {desc}")
            
            high_entropy = embedded_files.get('high_entropy_regions', [])
            if high_entropy:
                lines.append("â”‚")
                lines.append("â”‚  ğŸš¨ High Entropy Regions:")
                for region in high_entropy[:3]:
                    offset = region.get('offset', 0)
                    entropy = region.get('entropy', 0)
                    lines.append(f"â”‚    @ 0x{offset:08X}: {entropy:.3f}")
            
            lines.append("â””" + "â”€" * 77)
            lines.append("")
        
        return lines
